{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to convert our model to '.pb' format so that we can convert it to onnx using tf2onnx.convert(), therefore we first load our '.keras' model and convert it to '.pb' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 11:05:49.202265: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-04-18 11:05:49.202290: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-04-18 11:05:49.202297: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-04-18 11:05:49.202316: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-18 11:05:49.202329: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/opt/miniconda3/envs/aditya/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 496 variables whereas the saved optimizer has 14 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./pose_classification_model/pose_classification_13:14:15_18831.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./pose_classification_model_pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./pose_classification_model_pb/assets\n"
     ]
    }
   ],
   "source": [
    "# We're saving the '.keras' model in '.pb' format, so that we can convert '.pb' format to '.onnx' using tf2onnx\n",
    "tf.saved_model.save(model, './pose_classification_model_pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whether the '.pb' model was correctly saved or not by performing an inference on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.saved_model.load('./pose_classification_model_pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature keys: ['serving_default']\n"
     ]
    }
   ],
   "source": [
    "# Access the model's signature\n",
    "signature_keys = list(loaded_model.signatures.keys())\n",
    "print(\"Signature keys:\", signature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the inference function from the model's signature\n",
    "inference_func = loaded_model.signatures[signature_keys[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 480, 640, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.load('005349821.npy')\n",
    "test_data = test_data.reshape(1, test_data.shape[0], test_data.shape[1], test_data.shape[2])\n",
    "test_data = tf.constant(test_data)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 11:06:26.375176: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=2>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = inference_func(test_data)\n",
    "output = tf.reshape(output['output_0'], (output['output_0'].shape[1]))\n",
    "tf.argmax(output) # output class=2 which is home-activities, thus models was saved correctly in '.pb' format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the 'pb' model to 'onnx' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/aditya/lib/python3.10/runpy.py:126: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2024-04-18 11:06:54,946 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "2024-04-18 11:06:54,948 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2024-04-18 11:07:00,833 - INFO - Signatures found in model: [serving_default].\n",
      "2024-04-18 11:07:00,833 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2024-04-18 11:07:00,834 - INFO - Output names: ['output_0']\n",
      "2024-04-18 11:07:05,789 - INFO - Using tensorflow=2.16.1, onnx=1.13.0, tf2onnx=1.16.1/15c810\n",
      "2024-04-18 11:07:05,789 - INFO - Using opset <onnx, 15>\n",
      "2024-04-18 11:07:05,979 - INFO - Computed 0 values for constant folding\n",
      "2024-04-18 11:07:06,414 - INFO - Optimizing ONNX model\n",
      "2024-04-18 11:07:09,369 - INFO - After optimization: Add -77 (109->32), Cast -32 (32->0), Concat -16 (16->0), Const -247 (464->217), GlobalAveragePool +17 (0->17), Identity -2 (2->0), ReduceMean -17 (17->0), Shape -16 (16->0), Slice -16 (16->0), Squeeze +1 (16->17), Transpose -201 (202->1), Unsqueeze -64 (64->0)\n",
      "2024-04-18 11:07:09,410 - INFO - \n",
      "2024-04-18 11:07:09,411 - INFO - Successfully converted TensorFlow model ./pose_classification_model_pb/ to ONNX\n",
      "2024-04-18 11:07:09,411 - INFO - Model inputs: ['inputs']\n",
      "2024-04-18 11:07:09,411 - INFO - Model outputs: ['output_0']\n",
      "2024-04-18 11:07:09,411 - INFO - ONNX model is saved at ./pose_classification_model/pose_classification_13:14:15_18831.onnx\n"
     ]
    }
   ],
   "source": [
    "! python -m tf2onnx.convert --saved-model ./pose_classification_model_pb/ --output ./pose_classification_model/pose_classification_13:14:15_18831.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx, onnxruntime\n",
    "import torch\n",
    "\n",
    "from onnx2pytorch import ConvertModel\n",
    "from torch.nn.utils import prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now let's load the corresponding onnx model and convert it to corresponding pytorch version\n",
    "pose_classification_onnx_model = onnx.load('./pose_classification_model/pose_classification_13:14:15_18831.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the 'onnx' model to 'torch' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/aditya/lib/python3.10/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n"
     ]
    }
   ],
   "source": [
    "pose_classification_pytorch_model = ConvertModel(pose_classification_onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pose_classification_pytorch_model, './pose_classification_model/pose_classificaiton_model_torch_0.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate baseline performance of the converted torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/processed/',\n",
       " 'train_4_channel_info',\n",
       " 'train_labels_pose_class',\n",
       " 'val_4_channel_info',\n",
       " 'val_labels_pose_class')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = '../Project2_Analysis_V_1.6/data/processed/'\n",
    "\n",
    "x_train_suffix = 'train_4_channel_info'\n",
    "y_train_suffix = 'train_labels_pose_class'\n",
    "\n",
    "x_val_suffix = 'val_4_channel_info'\n",
    "y_val_suffix = 'val_labels_pose_class'\n",
    "dataset_path, x_train_suffix, y_train_suffix, x_val_suffix, y_val_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = os.listdir(f'{dataset_path}/{x_train_suffix}')\n",
    "y_train = os.listdir(f'{dataset_path}/{y_train_suffix}')\n",
    "x_train.sort(), y_train.sort() # so that they matchup i.e x_train[0] labels y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = os.listdir(f'{dataset_path}/{x_val_suffix}')\n",
    "y_val = os.listdir(f'{dataset_path}/{y_val_suffix}')\n",
    "x_val.sort(), y_val.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.data_loader import data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Train=> len_X: 2528 len_Y: 2528\n",
      "[+] Val=> len_X: 1094 len_Y: 1094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 11:41:09.305217: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-04-18 11:41:09.305251: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-04-18 11:41:09.305258: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-04-18 11:41:09.305309: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-18 11:41:09.305327: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = data_loader(dataset_path, x_train, y_train, x_val, y_val, x_train_suffix, y_train_suffix, x_val_suffix, y_val_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 11:41:18.409306: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Total Batches in validation dataset 69\n"
     ]
    }
   ],
   "source": [
    "total_batches_val = len(list(val_dataset))\n",
    "print(f\"[+] Total Batches in validation dataset {total_batches_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we converted an onnx model to torch model thus we used ConvertModel() method for this. And ConvertModel() does not support batch sizes > 1.<br>\n",
    "Thus we convert the 32 batches to 1 batch input, also val_dataset has tensorflow tensors and we need to convert them to torch.tensor in the loop, these are the reasons why validation process is a little slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvertModel(\n",
       "  (Transpose_StatefulPartitionedCall/functional_1_1/conv2d_1/convolution__6:0): Transpose()\n",
       "  (Conv_Conv__682:0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Conv_Conv__684:0): Conv2d(4, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/rescaling_1/mul:0): mul()\n",
       "  (Sub_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/normalization_1/Sub:0): mul()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/normalization_1/truediv:0): mul()\n",
       "  (Conv_Conv__692:0): Sequential(\n",
       "    (0): ConstantPad2d(padding=(0, 1, 0, 1), value=0)\n",
       "    (1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/stem_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/stem_activation_1/mul_1:0): mul()\n",
       "  (Conv_Conv__698:0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block1a_project_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block1a_project_activation_1/mul_1:0): mul()\n",
       "  (Conv_Conv__704:0): Sequential(\n",
       "    (0): ConstantPad2d(padding=(0, 1, 0, 1), value=0)\n",
       "    (1): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block2a_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block2a_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_Conv__710:0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_Conv__716:0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block2b_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block2b_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_Conv__722:0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block2b_add_1/Add:0): Add()\n",
       "  (Conv_Conv__724:0): Sequential(\n",
       "    (0): ConstantPad2d(padding=(0, 1, 0, 1), value=0)\n",
       "    (1): Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block3a_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block3a_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_Conv__730:0): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_Conv__736:0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block3b_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block3b_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_Conv__742:0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block3b_add_1/Add:0): Add()\n",
       "  (Conv_Conv__744:0): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_dwconv2_1/depthwise:0): Sequential(\n",
       "    (0): ConstantPad2d(padding=(0, 1, 0, 1), value=0)\n",
       "    (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "  )\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_squeeze_1/Mean_Squeeze__1465:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_reduce_1/convolution__81:0): Reshape(shape=[ -1 192   1   1])\n",
       "  (Conv_Conv__760:0): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_expand_1/convolution__85:0): Reshape(shape=[-1 12  1  1])\n",
       "  (Conv_Conv__766:0): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__768:0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_Conv__774:0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_dwconv2_1/depthwise:0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_squeeze_1/Mean_Squeeze__1445:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_reduce_1/convolution__120:0): Reshape(shape=[ -1 384   1   1])\n",
       "  (Conv_Conv__790:0): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_expand_1/convolution__124:0): Reshape(shape=[-1 24  1  1])\n",
       "  (Conv_Conv__796:0): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__798:0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_add_1/Add:0): Add()\n",
       "  (Conv_Conv__804:0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_dwconv2_1/depthwise:0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_squeeze_1/Mean_Squeeze__1463:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_reduce_1/convolution__159:0): Reshape(shape=[ -1 384   1   1])\n",
       "  (Conv_Conv__820:0): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_expand_1/convolution__163:0): Reshape(shape=[-1 24  1  1])\n",
       "  (Conv_Conv__826:0): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__828:0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_add_1/Add:0): Add()\n",
       "  (Conv_Conv__830:0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_dwconv2_1/depthwise:0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_squeeze_1/Mean_Squeeze__1457:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_reduce_1/convolution__198:0): Reshape(shape=[ -1 576   1   1])\n",
       "  (Conv_Conv__846:0): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_expand_1/convolution__202:0): Reshape(shape=[-1 24  1  1])\n",
       "  (Conv_Conv__852:0): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__854:0): Conv2d(576, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_Conv__860:0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_dwconv2_1/depthwise:0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_squeeze_1/Mean_Squeeze__1451:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_reduce_1/convolution__237:0): Reshape(shape=[ -1 672   1   1])\n",
       "  (Conv_Conv__876:0): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_expand_1/convolution__241:0): Reshape(shape=[-1 28  1  1])\n",
       "  (Conv_Conv__882:0): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__884:0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_add_1/Add:0): Add()\n",
       "  (Conv_Conv__890:0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_dwconv2_1/depthwise:0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_squeeze_1/Mean_Squeeze__1449:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_reduce_1/convolution__276:0): Reshape(shape=[ -1 672   1   1])\n",
       "  (Conv_Conv__906:0): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_expand_1/convolution__280:0): Reshape(shape=[-1 28  1  1])\n",
       "  (Conv_Conv__912:0): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__914:0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_add_1/Add:0): Add()\n",
       "  (Conv_Conv__920:0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_dwconv2_1/depthwise:0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_squeeze_1/Mean_Squeeze__1475:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_reduce_1/convolution__315:0): Reshape(shape=[ -1 672   1   1])\n",
       "  (Conv_Conv__936:0): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_expand_1/convolution__319:0): Reshape(shape=[-1 28  1  1])\n",
       "  (Conv_Conv__942:0): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__944:0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_add_1/Add:0): Add()\n",
       "  (Conv_Conv__950:0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_dwconv2_1/depthwise:0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_squeeze_1/Mean_Squeeze__1471:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_reduce_1/convolution__354:0): Reshape(shape=[ -1 672   1   1])\n",
       "  (Conv_Conv__966:0): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_expand_1/convolution__358:0): Reshape(shape=[-1 28  1  1])\n",
       "  (Conv_Conv__972:0): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__974:0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_add_1/Add:0): Add()\n",
       "  (Conv_Conv__976:0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_dwconv2_1/depthwise:0): Sequential(\n",
       "    (0): ConstantPad2d(padding=(0, 1, 0, 1), value=0)\n",
       "    (1): Conv2d(672, 672, kernel_size=(3, 3), stride=(2, 2), groups=672, bias=False)\n",
       "  )\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_squeeze_1/Mean_Squeeze__1447:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_reduce_1/convolution__393:0): Reshape(shape=[ -1 672   1   1])\n",
       "  (Conv_Conv__992:0): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_expand_1/convolution__397:0): Reshape(shape=[-1 28  1  1])\n",
       "  (Conv_Conv__998:0): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1000:0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_Conv__1006:0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_dwconv2_1/depthwise:0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_squeeze_1/Mean_Squeeze__1459:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_reduce_1/convolution__432:0): Reshape(shape=[  -1 1152    1    1])\n",
       "  (Conv_Conv__1022:0): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_expand_1/convolution__436:0): Reshape(shape=[-1 48  1  1])\n",
       "  (Conv_Conv__1028:0): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1030:0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_add_1/Add:0): Add()\n",
       "  (Conv_Conv__1036:0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_dwconv2_1/depthwise:0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_squeeze_1/Mean_Squeeze__1443:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_reduce_1/convolution__471:0): Reshape(shape=[  -1 1152    1    1])\n",
       "  (Conv_Conv__1052:0): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_expand_1/convolution__475:0): Reshape(shape=[-1 48  1  1])\n",
       "  (Conv_Conv__1058:0): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1060:0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_add_1/Add:0): Add()\n",
       "  (Conv_Conv__1066:0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_dwconv2_1/depthwise:0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_squeeze_1/Mean_Squeeze__1461:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_reduce_1/convolution__510:0): Reshape(shape=[  -1 1152    1    1])\n",
       "  (Conv_Conv__1082:0): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_expand_1/convolution__514:0): Reshape(shape=[-1 48  1  1])\n",
       "  (Conv_Conv__1088:0): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1090:0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_add_1/Add:0): Add()\n",
       "  (Conv_Conv__1096:0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_dwconv2_1/depthwise:0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_squeeze_1/Mean_Squeeze__1473:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_reduce_1/convolution__549:0): Reshape(shape=[  -1 1152    1    1])\n",
       "  (Conv_Conv__1112:0): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_expand_1/convolution__553:0): Reshape(shape=[-1 48  1  1])\n",
       "  (Conv_Conv__1118:0): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1120:0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_add_1/Add:0): Add()\n",
       "  (Conv_Conv__1126:0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_dwconv2_1/depthwise:0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_squeeze_1/Mean_Squeeze__1455:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_reduce_1/convolution__588:0): Reshape(shape=[  -1 1152    1    1])\n",
       "  (Conv_Conv__1142:0): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_expand_1/convolution__592:0): Reshape(shape=[-1 48  1  1])\n",
       "  (Conv_Conv__1148:0): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1150:0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_add_1/Add:0): Add()\n",
       "  (Conv_Conv__1156:0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_dwconv2_1/depthwise:0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_squeeze_1/Mean_Squeeze__1469:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_reduce_1/convolution__627:0): Reshape(shape=[  -1 1152    1    1])\n",
       "  (Conv_Conv__1172:0): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_expand_1/convolution__631:0): Reshape(shape=[-1 48  1  1])\n",
       "  (Conv_Conv__1178:0): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1180:0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_add_1/Add:0): Add()\n",
       "  (Conv_Conv__1186:0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_dwconv2_1/depthwise:0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_squeeze_1/Mean_Squeeze__1467:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_reduce_1/convolution__666:0): Reshape(shape=[  -1 1152    1    1])\n",
       "  (Conv_Conv__1202:0): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_expand_1/convolution__670:0): Reshape(shape=[-1 48  1  1])\n",
       "  (Conv_Conv__1208:0): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1210:0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_add_1/Add:0): Add()\n",
       "  (Conv_Conv__1212:0): Conv2d(192, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/top_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/top_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/global_average_pooling_layer_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/global_average_pooling_layer_1/Mean_Squeeze__1453:0): Squeeze()\n",
       "  (MatMul_StatefulPartitionedCall/functional_1_1/output_layer_1/add:0): Linear(in_features=1280, out_features=20, bias=True)\n",
       "  (Softmax_output_0): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_classification_pytorch_model.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, val_dataset, total):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    batch_count = 0\n",
    "    with torch.no_grad(): \n",
    "        for batch in val_dataset:\n",
    "            inputs = (torch.from_numpy(batch[0].numpy())).to('mps') # This is done because val_dataset has tensorflow tensors, so we need to convert them to torch tensors\n",
    "            labels = (torch.from_numpy(batch[1].numpy())).to('mps') # Move the tensors to 'mps' to use Mac GPU\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                feed_input = (inputs[i]).view(1, inputs.shape[1], inputs.shape[2], inputs.shape[3])\n",
    "                feed_label = (labels[i]).view(1,).int()\n",
    "                \n",
    "                output = model(feed_input)\n",
    "                predicted_class = torch.argmax(output)\n",
    "                \n",
    "                if predicted_class == feed_label[0]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "            batch_count += 1\n",
    "            print(f\"[+] Validation Batch No: {batch_count} done. Percent Completion: {(batch_count / total_batches_val) * 100}\")\n",
    "    return (correct / total) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Validation Batch No: 1 done. Percent Completion: 1.4492753623188406\n",
      "[+] Validation Batch No: 2 done. Percent Completion: 2.898550724637681\n",
      "[+] Validation Batch No: 3 done. Percent Completion: 4.3478260869565215\n",
      "[+] Validation Batch No: 4 done. Percent Completion: 5.797101449275362\n",
      "[+] Validation Batch No: 5 done. Percent Completion: 7.246376811594203\n",
      "[+] Validation Batch No: 6 done. Percent Completion: 8.695652173913043\n",
      "[+] Validation Batch No: 7 done. Percent Completion: 10.144927536231885\n",
      "[+] Validation Batch No: 8 done. Percent Completion: 11.594202898550725\n",
      "[+] Validation Batch No: 9 done. Percent Completion: 13.043478260869565\n",
      "[+] Validation Batch No: 10 done. Percent Completion: 14.492753623188406\n",
      "[+] Validation Batch No: 11 done. Percent Completion: 15.942028985507244\n",
      "[+] Validation Batch No: 12 done. Percent Completion: 17.391304347826086\n",
      "[+] Validation Batch No: 13 done. Percent Completion: 18.84057971014493\n",
      "[+] Validation Batch No: 14 done. Percent Completion: 20.28985507246377\n",
      "[+] Validation Batch No: 15 done. Percent Completion: 21.73913043478261\n",
      "[+] Validation Batch No: 16 done. Percent Completion: 23.18840579710145\n",
      "[+] Validation Batch No: 17 done. Percent Completion: 24.637681159420293\n",
      "[+] Validation Batch No: 18 done. Percent Completion: 26.08695652173913\n",
      "[+] Validation Batch No: 19 done. Percent Completion: 27.536231884057973\n",
      "[+] Validation Batch No: 20 done. Percent Completion: 28.985507246376812\n",
      "[+] Validation Batch No: 21 done. Percent Completion: 30.434782608695656\n",
      "[+] Validation Batch No: 22 done. Percent Completion: 31.88405797101449\n",
      "[+] Validation Batch No: 23 done. Percent Completion: 33.33333333333333\n",
      "[+] Validation Batch No: 24 done. Percent Completion: 34.78260869565217\n",
      "[+] Validation Batch No: 25 done. Percent Completion: 36.231884057971016\n",
      "[+] Validation Batch No: 26 done. Percent Completion: 37.68115942028986\n",
      "[+] Validation Batch No: 27 done. Percent Completion: 39.130434782608695\n",
      "[+] Validation Batch No: 28 done. Percent Completion: 40.57971014492754\n",
      "[+] Validation Batch No: 29 done. Percent Completion: 42.028985507246375\n",
      "[+] Validation Batch No: 30 done. Percent Completion: 43.47826086956522\n",
      "[+] Validation Batch No: 31 done. Percent Completion: 44.927536231884055\n",
      "[+] Validation Batch No: 32 done. Percent Completion: 46.3768115942029\n",
      "[+] Validation Batch No: 33 done. Percent Completion: 47.82608695652174\n",
      "[+] Validation Batch No: 34 done. Percent Completion: 49.275362318840585\n",
      "[+] Validation Batch No: 35 done. Percent Completion: 50.72463768115942\n",
      "[+] Validation Batch No: 36 done. Percent Completion: 52.17391304347826\n",
      "[+] Validation Batch No: 37 done. Percent Completion: 53.62318840579711\n",
      "[+] Validation Batch No: 38 done. Percent Completion: 55.072463768115945\n",
      "[+] Validation Batch No: 39 done. Percent Completion: 56.52173913043478\n",
      "[+] Validation Batch No: 40 done. Percent Completion: 57.971014492753625\n",
      "[+] Validation Batch No: 41 done. Percent Completion: 59.42028985507246\n",
      "[+] Validation Batch No: 42 done. Percent Completion: 60.86956521739131\n",
      "[+] Validation Batch No: 43 done. Percent Completion: 62.31884057971014\n",
      "[+] Validation Batch No: 44 done. Percent Completion: 63.76811594202898\n",
      "[+] Validation Batch No: 45 done. Percent Completion: 65.21739130434783\n",
      "[+] Validation Batch No: 46 done. Percent Completion: 66.66666666666666\n",
      "[+] Validation Batch No: 47 done. Percent Completion: 68.11594202898551\n",
      "[+] Validation Batch No: 48 done. Percent Completion: 69.56521739130434\n",
      "[+] Validation Batch No: 49 done. Percent Completion: 71.01449275362319\n",
      "[+] Validation Batch No: 50 done. Percent Completion: 72.46376811594203\n",
      "[+] Validation Batch No: 51 done. Percent Completion: 73.91304347826086\n",
      "[+] Validation Batch No: 52 done. Percent Completion: 75.36231884057972\n",
      "[+] Validation Batch No: 53 done. Percent Completion: 76.81159420289855\n",
      "[+] Validation Batch No: 54 done. Percent Completion: 78.26086956521739\n",
      "[+] Validation Batch No: 55 done. Percent Completion: 79.71014492753623\n",
      "[+] Validation Batch No: 56 done. Percent Completion: 81.15942028985508\n",
      "[+] Validation Batch No: 57 done. Percent Completion: 82.6086956521739\n",
      "[+] Validation Batch No: 58 done. Percent Completion: 84.05797101449275\n",
      "[+] Validation Batch No: 59 done. Percent Completion: 85.5072463768116\n",
      "[+] Validation Batch No: 60 done. Percent Completion: 86.95652173913044\n",
      "[+] Validation Batch No: 61 done. Percent Completion: 88.40579710144928\n",
      "[+] Validation Batch No: 62 done. Percent Completion: 89.85507246376811\n",
      "[+] Validation Batch No: 63 done. Percent Completion: 91.30434782608695\n",
      "[+] Validation Batch No: 64 done. Percent Completion: 92.7536231884058\n",
      "[+] Validation Batch No: 65 done. Percent Completion: 94.20289855072464\n",
      "[+] Validation Batch No: 66 done. Percent Completion: 95.65217391304348\n",
      "[+] Validation Batch No: 67 done. Percent Completion: 97.10144927536231\n",
      "[+] Validation Batch No: 68 done. Percent Completion: 98.55072463768117\n",
      "[+] Validation Batch No: 69 done. Percent Completion: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 11:11:11.538387: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "accuracy = validate_model(pose_classification_pytorch_model, val_dataset, total_batches_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Accuracy of baseline model: 61.24314442413162\n"
     ]
    }
   ],
   "source": [
    "print(f\"[+] Accuracy of baseline model: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unstructured Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement a type of pruning-aware training, i.e, we will fine-tune the pruned model to recover the losses in accuracy due to pruning while maintaing almost similar pruning percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvertModel(\n",
       "  (Transpose_StatefulPartitionedCall/functional_1_1/conv2d_1/convolution__6:0): Transpose()\n",
       "  (Conv_Conv__682:0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Conv_Conv__684:0): Conv2d(4, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/rescaling_1/mul:0): mul()\n",
       "  (Sub_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/normalization_1/Sub:0): mul()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/normalization_1/truediv:0): mul()\n",
       "  (Conv_Conv__692:0): Sequential(\n",
       "    (0): ConstantPad2d(padding=(0, 1, 0, 1), value=0)\n",
       "    (1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/stem_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/stem_activation_1/mul_1:0): mul()\n",
       "  (Conv_Conv__698:0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block1a_project_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block1a_project_activation_1/mul_1:0): mul()\n",
       "  (Conv_Conv__704:0): Sequential(\n",
       "    (0): ConstantPad2d(padding=(0, 1, 0, 1), value=0)\n",
       "    (1): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block2a_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block2a_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_Conv__710:0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_Conv__716:0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block2b_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block2b_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_Conv__722:0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block2b_add_1/Add:0): Add()\n",
       "  (Conv_Conv__724:0): Sequential(\n",
       "    (0): ConstantPad2d(padding=(0, 1, 0, 1), value=0)\n",
       "    (1): Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block3a_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block3a_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_Conv__730:0): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_Conv__736:0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block3b_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block3b_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_Conv__742:0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block3b_add_1/Add:0): Add()\n",
       "  (Conv_Conv__744:0): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_dwconv2_1/depthwise:0): Sequential(\n",
       "    (0): ConstantPad2d(padding=(0, 1, 0, 1), value=0)\n",
       "    (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "  )\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_squeeze_1/Mean_Squeeze__1465:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_reduce_1/convolution__81:0): Reshape(shape=[ -1 192   1   1])\n",
       "  (Conv_Conv__760:0): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_expand_1/convolution__85:0): Reshape(shape=[-1 12  1  1])\n",
       "  (Conv_Conv__766:0): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4a_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__768:0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_Conv__774:0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_dwconv2_1/depthwise:0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_squeeze_1/Mean_Squeeze__1445:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_reduce_1/convolution__120:0): Reshape(shape=[ -1 384   1   1])\n",
       "  (Conv_Conv__790:0): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_expand_1/convolution__124:0): Reshape(shape=[-1 24  1  1])\n",
       "  (Conv_Conv__796:0): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__798:0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4b_add_1/Add:0): Add()\n",
       "  (Conv_Conv__804:0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_dwconv2_1/depthwise:0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_squeeze_1/Mean_Squeeze__1463:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_reduce_1/convolution__159:0): Reshape(shape=[ -1 384   1   1])\n",
       "  (Conv_Conv__820:0): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_expand_1/convolution__163:0): Reshape(shape=[-1 24  1  1])\n",
       "  (Conv_Conv__826:0): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__828:0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block4c_add_1/Add:0): Add()\n",
       "  (Conv_Conv__830:0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_dwconv2_1/depthwise:0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_squeeze_1/Mean_Squeeze__1457:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_reduce_1/convolution__198:0): Reshape(shape=[ -1 576   1   1])\n",
       "  (Conv_Conv__846:0): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_expand_1/convolution__202:0): Reshape(shape=[-1 24  1  1])\n",
       "  (Conv_Conv__852:0): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5a_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__854:0): Conv2d(576, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_Conv__860:0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_dwconv2_1/depthwise:0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_squeeze_1/Mean_Squeeze__1451:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_reduce_1/convolution__237:0): Reshape(shape=[ -1 672   1   1])\n",
       "  (Conv_Conv__876:0): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_expand_1/convolution__241:0): Reshape(shape=[-1 28  1  1])\n",
       "  (Conv_Conv__882:0): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__884:0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5b_add_1/Add:0): Add()\n",
       "  (Conv_Conv__890:0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_dwconv2_1/depthwise:0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_squeeze_1/Mean_Squeeze__1449:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_reduce_1/convolution__276:0): Reshape(shape=[ -1 672   1   1])\n",
       "  (Conv_Conv__906:0): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_expand_1/convolution__280:0): Reshape(shape=[-1 28  1  1])\n",
       "  (Conv_Conv__912:0): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__914:0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5c_add_1/Add:0): Add()\n",
       "  (Conv_Conv__920:0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_dwconv2_1/depthwise:0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_squeeze_1/Mean_Squeeze__1475:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_reduce_1/convolution__315:0): Reshape(shape=[ -1 672   1   1])\n",
       "  (Conv_Conv__936:0): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_expand_1/convolution__319:0): Reshape(shape=[-1 28  1  1])\n",
       "  (Conv_Conv__942:0): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__944:0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5d_add_1/Add:0): Add()\n",
       "  (Conv_Conv__950:0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_dwconv2_1/depthwise:0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_squeeze_1/Mean_Squeeze__1471:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_reduce_1/convolution__354:0): Reshape(shape=[ -1 672   1   1])\n",
       "  (Conv_Conv__966:0): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_expand_1/convolution__358:0): Reshape(shape=[-1 28  1  1])\n",
       "  (Conv_Conv__972:0): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__974:0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block5e_add_1/Add:0): Add()\n",
       "  (Conv_Conv__976:0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_dwconv2_1/depthwise:0): Sequential(\n",
       "    (0): ConstantPad2d(padding=(0, 1, 0, 1), value=0)\n",
       "    (1): Conv2d(672, 672, kernel_size=(3, 3), stride=(2, 2), groups=672, bias=False)\n",
       "  )\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_squeeze_1/Mean_Squeeze__1447:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_reduce_1/convolution__393:0): Reshape(shape=[ -1 672   1   1])\n",
       "  (Conv_Conv__992:0): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_expand_1/convolution__397:0): Reshape(shape=[-1 28  1  1])\n",
       "  (Conv_Conv__998:0): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6a_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1000:0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_Conv__1006:0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_dwconv2_1/depthwise:0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_squeeze_1/Mean_Squeeze__1459:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_reduce_1/convolution__432:0): Reshape(shape=[  -1 1152    1    1])\n",
       "  (Conv_Conv__1022:0): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_expand_1/convolution__436:0): Reshape(shape=[-1 48  1  1])\n",
       "  (Conv_Conv__1028:0): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1030:0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6b_add_1/Add:0): Add()\n",
       "  (Conv_Conv__1036:0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_dwconv2_1/depthwise:0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_squeeze_1/Mean_Squeeze__1443:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_reduce_1/convolution__471:0): Reshape(shape=[  -1 1152    1    1])\n",
       "  (Conv_Conv__1052:0): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_expand_1/convolution__475:0): Reshape(shape=[-1 48  1  1])\n",
       "  (Conv_Conv__1058:0): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1060:0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6c_add_1/Add:0): Add()\n",
       "  (Conv_Conv__1066:0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_dwconv2_1/depthwise:0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_squeeze_1/Mean_Squeeze__1461:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_reduce_1/convolution__510:0): Reshape(shape=[  -1 1152    1    1])\n",
       "  (Conv_Conv__1082:0): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_expand_1/convolution__514:0): Reshape(shape=[-1 48  1  1])\n",
       "  (Conv_Conv__1088:0): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1090:0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6d_add_1/Add:0): Add()\n",
       "  (Conv_Conv__1096:0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_dwconv2_1/depthwise:0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_squeeze_1/Mean_Squeeze__1473:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_reduce_1/convolution__549:0): Reshape(shape=[  -1 1152    1    1])\n",
       "  (Conv_Conv__1112:0): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_expand_1/convolution__553:0): Reshape(shape=[-1 48  1  1])\n",
       "  (Conv_Conv__1118:0): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1120:0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6e_add_1/Add:0): Add()\n",
       "  (Conv_Conv__1126:0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_dwconv2_1/depthwise:0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_squeeze_1/Mean_Squeeze__1455:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_reduce_1/convolution__588:0): Reshape(shape=[  -1 1152    1    1])\n",
       "  (Conv_Conv__1142:0): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_expand_1/convolution__592:0): Reshape(shape=[-1 48  1  1])\n",
       "  (Conv_Conv__1148:0): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1150:0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6f_add_1/Add:0): Add()\n",
       "  (Conv_Conv__1156:0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_dwconv2_1/depthwise:0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_squeeze_1/Mean_Squeeze__1469:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_reduce_1/convolution__627:0): Reshape(shape=[  -1 1152    1    1])\n",
       "  (Conv_Conv__1172:0): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_expand_1/convolution__631:0): Reshape(shape=[-1 48  1  1])\n",
       "  (Conv_Conv__1178:0): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1180:0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6g_add_1/Add:0): Add()\n",
       "  (Conv_Conv__1186:0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_expand_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_expand_activation_1/mul_1:0): mul()\n",
       "  (Conv_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_dwconv2_1/depthwise:0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_bn_1/batchnorm/mul_1:0): mul()\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_bn_1/batchnorm/add_1:0): Add()\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_squeeze_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_squeeze_1/Mean_Squeeze__1467:0): Squeeze()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_reduce_1/convolution__666:0): Reshape(shape=[  -1 1152    1    1])\n",
       "  (Conv_Conv__1202:0): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_reduce_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_reduce_1/mul_1:0): mul()\n",
       "  (Reshape_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_expand_1/convolution__670:0): Reshape(shape=[-1 48  1  1])\n",
       "  (Conv_Conv__1208:0): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_expand_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_se_excite_1/Mul:0): mul()\n",
       "  (Conv_Conv__1210:0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/block6h_add_1/Add:0): Add()\n",
       "  (Conv_Conv__1212:0): Conv2d(192, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Sigmoid_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/top_activation_1/Sigmoid:0): Sigmoid()\n",
       "  (Mul_StatefulPartitionedCall/functional_1_1/efficientnetv2-b0_1/top_activation_1/mul_1:0): mul()\n",
       "  (GlobalAveragePool_StatefulPartitionedCall/functional_1_1/global_average_pooling_layer_1/Mean:0): GlobalAveragePool()\n",
       "  (Squeeze_StatefulPartitionedCall/functional_1_1/global_average_pooling_layer_1/Mean_Squeeze__1453:0): Squeeze()\n",
       "  (MatMul_StatefulPartitionedCall/functional_1_1/output_layer_1/add:0): Linear(in_features=1280, out_features=20, bias=True)\n",
       "  (Softmax_output_0): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print the model to see the input and output shapes of each layer, this will help to decide the pruning ratios, for layers with more inputs or outputs\n",
    "# we will keep pruning ratio higher, and we will also increase the pruning for the conv layers at the end of the model\n",
    "# Like (1): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2)) means this convolutional layer has 16 feature maps as i/p and 64 feature maps as o/p\n",
    "pose_classification_pytorch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.utils import find_unstructured_prune_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code is used to see what types of convolutional layers are present and the number of parameters in them, so that we can set the pruning ratio accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+]  Conv_Conv__682:0.weight  num_params:  148\n",
      "[+]  Conv_Conv__684:0.weight  num_params:  111\n",
      "[+]  Conv_Conv__692:0.1.weight  num_params:  896\n",
      "[+]  Conv_Conv__698:0.weight  num_params:  4624\n",
      "[+]  Conv_Conv__704:0.1.weight  num_params:  9280\n",
      "[+]  Conv_Conv__710:0.weight  num_params:  2080\n",
      "[+]  Conv_Conv__716:0.weight  num_params:  36992\n",
      "[+]  Conv_Conv__722:0.weight  num_params:  4128\n",
      "[+]  Conv_Conv__724:0.1.weight  num_params:  36992\n",
      "[+]  Conv_Conv__730:0.weight  num_params:  6192\n",
      "[+]  Conv_Conv__736:0.weight  num_params:  83136\n",
      "[+]  Conv_Conv__742:0.weight  num_params:  9264\n",
      "[+]  Conv_Conv__744:0.weight  num_params:  9408\n",
      "[+]  Conv_Conv__760:0.weight  num_params:  2316\n",
      "[+]  Conv_Conv__766:0.weight  num_params:  2496\n",
      "[+]  Conv_Conv__768:0.weight  num_params:  18528\n",
      "[+]  Conv_Conv__774:0.weight  num_params:  37248\n",
      "[+]  Conv_Conv__790:0.weight  num_params:  9240\n",
      "[+]  Conv_Conv__796:0.weight  num_params:  9600\n",
      "[+]  Conv_Conv__798:0.weight  num_params:  36960\n",
      "[+]  Conv_Conv__804:0.weight  num_params:  37248\n",
      "[+]  Conv_Conv__820:0.weight  num_params:  9240\n",
      "[+]  Conv_Conv__826:0.weight  num_params:  9600\n",
      "[+]  Conv_Conv__828:0.weight  num_params:  36960\n",
      "[+]  Conv_Conv__830:0.weight  num_params:  55872\n",
      "[+]  Conv_Conv__846:0.weight  num_params:  13848\n",
      "[+]  Conv_Conv__852:0.weight  num_params:  14400\n",
      "[+]  Conv_Conv__854:0.weight  num_params:  64624\n",
      "[+]  Conv_Conv__860:0.weight  num_params:  75936\n",
      "[+]  Conv_Conv__876:0.weight  num_params:  18844\n",
      "[+]  Conv_Conv__882:0.weight  num_params:  19488\n",
      "[+]  Conv_Conv__884:0.weight  num_params:  75376\n",
      "[+]  Conv_Conv__890:0.weight  num_params:  75936\n",
      "[+]  Conv_Conv__906:0.weight  num_params:  18844\n",
      "[+]  Conv_Conv__912:0.weight  num_params:  19488\n",
      "[+]  Conv_Conv__914:0.weight  num_params:  75376\n",
      "[+]  Conv_Conv__920:0.weight  num_params:  75936\n",
      "[+]  Conv_Conv__936:0.weight  num_params:  18844\n",
      "[+]  Conv_Conv__942:0.weight  num_params:  19488\n",
      "[+]  Conv_Conv__944:0.weight  num_params:  75376\n",
      "[+]  Conv_Conv__950:0.weight  num_params:  75936\n",
      "[+]  Conv_Conv__966:0.weight  num_params:  18844\n",
      "[+]  Conv_Conv__972:0.weight  num_params:  19488\n",
      "[+]  Conv_Conv__974:0.weight  num_params:  75376\n",
      "[+]  Conv_Conv__976:0.weight  num_params:  75936\n",
      "[+]  Conv_Conv__992:0.weight  num_params:  18844\n",
      "[+]  Conv_Conv__998:0.weight  num_params:  19488\n",
      "[+]  Conv_Conv__1000:0.weight  num_params:  129216\n",
      "[+]  Conv_Conv__1006:0.weight  num_params:  222336\n",
      "[+]  Conv_Conv__1022:0.weight  num_params:  55344\n",
      "[+]  Conv_Conv__1028:0.weight  num_params:  56448\n",
      "[+]  Conv_Conv__1030:0.weight  num_params:  221376\n",
      "[+]  Conv_Conv__1036:0.weight  num_params:  222336\n",
      "[+]  Conv_Conv__1052:0.weight  num_params:  55344\n",
      "[+]  Conv_Conv__1058:0.weight  num_params:  56448\n",
      "[+]  Conv_Conv__1060:0.weight  num_params:  221376\n",
      "[+]  Conv_Conv__1066:0.weight  num_params:  222336\n",
      "[+]  Conv_Conv__1082:0.weight  num_params:  55344\n",
      "[+]  Conv_Conv__1088:0.weight  num_params:  56448\n",
      "[+]  Conv_Conv__1090:0.weight  num_params:  221376\n",
      "[+]  Conv_Conv__1096:0.weight  num_params:  222336\n",
      "[+]  Conv_Conv__1112:0.weight  num_params:  55344\n",
      "[+]  Conv_Conv__1118:0.weight  num_params:  56448\n",
      "[+]  Conv_Conv__1120:0.weight  num_params:  221376\n",
      "[+]  Conv_Conv__1126:0.weight  num_params:  222336\n",
      "[+]  Conv_Conv__1142:0.weight  num_params:  55344\n",
      "[+]  Conv_Conv__1148:0.weight  num_params:  56448\n",
      "[+]  Conv_Conv__1150:0.weight  num_params:  221376\n",
      "[+]  Conv_Conv__1156:0.weight  num_params:  222336\n",
      "[+]  Conv_Conv__1172:0.weight  num_params:  55344\n",
      "[+]  Conv_Conv__1178:0.weight  num_params:  56448\n",
      "[+]  Conv_Conv__1180:0.weight  num_params:  221376\n",
      "[+]  Conv_Conv__1186:0.weight  num_params:  222336\n",
      "[+]  Conv_Conv__1202:0.weight  num_params:  55344\n",
      "[+]  Conv_Conv__1208:0.weight  num_params:  56448\n",
      "[+]  Conv_Conv__1210:0.weight  num_params:  221376\n",
      "[+]  Conv_Conv__1212:0.weight  num_params:  247040\n"
     ]
    }
   ],
   "source": [
    "for element in pose_classification_pytorch_model.named_parameters():\n",
    "    if ('Conv_Conv' in element[0]) and ('weight' in element[0]):\n",
    "        layer_num = None\n",
    "        if (element[0][14] >= '0' and element[0][14] <= '9'):\n",
    "            layer_num = int(element[0][11:15])\n",
    "        else:\n",
    "            layer_num = int(element[0][11:14])\n",
    "        # print(element[0], layer_num)\n",
    "\n",
    "        # Calculate the number of parmaters in the current convolutional layer\n",
    "        inputs, outputs = element[1].shape[1], element[1].shape[0]\n",
    "        kernel_w, kernel_h = element[1].shape[2], element[1].shape[3]\n",
    "        num_params = (kernel_h * kernel_w * inputs + 1) * outputs\n",
    "\n",
    "        print(\"[+] \", element[0], \" num_params: \", num_params)\n",
    "        # Check the layer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_ratio_dict = {\n",
    "    '800': [0.15, 0.20, 0.20, 0.25, 0.25, 0.40, 0.40], # prune ratios for convolutional layers in range 800 to 900(exclusive)\n",
    "    '900': [0.15, 0.15, 0.20, 0.20, 0.30, 0.40, 0.40],\n",
    "    '1000': [0.15, 0.25, 0.25, 0.30, 0.40, 0.40, 0.50],\n",
    "    '1100': [0.20, 0.25, 0.25, 0.30, 0.40, 0.40, 0.50],\n",
    "    '1200': [0.20, 0.25, 0.25, 0.30, 0.50, 0.55, 0.60]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Pruning completed\n"
     ]
    }
   ],
   "source": [
    "for name, module in pose_classification_pytorch_model.named_modules():\n",
    "    if 'Conv_Conv' in name:\n",
    "        # print((list(module.named_parameters())[0])[1].shape)\n",
    "        layer_num = None\n",
    "        if (name[14] >= '0' and name[14] <= '9'):\n",
    "            layer_num = int(name[11:15])\n",
    "        else:\n",
    "            layer_num = int(name[11:14])\n",
    "        \n",
    "        if layer_num < 800: # layers that have layer_num < 800 are ignored\n",
    "            continue\n",
    "        weight_matrix_shape = (list(module.named_parameters())[0][1]).shape\n",
    "        \n",
    "        num_params = module.weight.numel() # basically mutiplies the shape tensor to get the number of params in the current layer\n",
    "        \n",
    "        if layer_num >= 800 and layer_num < 900:\n",
    "            if num_params < 15000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['800'][0])\n",
    "            elif num_params >= 15000 and num_params < 40000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['800'][1])\n",
    "            elif num_params >= 40000 and num_params < 70000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['800'][2])\n",
    "            elif num_params >= 70000 and num_params < 100000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['800'][3])\n",
    "            elif num_params >= 100000 and num_params < 150000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['800'][4])\n",
    "            elif num_params >= 150000 and num_params < 200000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['800'][5])\n",
    "            else:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['800'][6])\n",
    "        elif layer_num >= 900 and layer_num < 1000:\n",
    "            if num_params < 15000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['900'][0])\n",
    "            elif num_params >= 15000 and num_params < 40000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['900'][1])\n",
    "            elif num_params >= 40000 and num_params < 70000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['900'][2])\n",
    "            elif num_params >= 70000 and num_params < 100000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['900'][3])\n",
    "            elif num_params >= 100000 and num_params < 150000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['900'][4])\n",
    "            elif num_params >= 150000 and num_params < 200000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['900'][5])\n",
    "            else:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['900'][6])\n",
    "        elif layer_num >= 1000 and layer_num < 1100:\n",
    "            if num_params < 15000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1000'][0])\n",
    "            elif num_params >= 15000 and num_params < 40000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1000'][1])\n",
    "            elif num_params >= 40000 and num_params < 70000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1000'][2])\n",
    "            elif num_params >= 70000 and num_params < 100000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1000'][3])\n",
    "            elif num_params >= 100000 and num_params < 150000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1000'][4])\n",
    "            elif num_params >= 150000 and num_params < 200000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1000'][5])\n",
    "            else:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1000'][6])\n",
    "        elif layer_num >= 1100 and layer_num < 1200:\n",
    "            if num_params < 15000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1100'][0])\n",
    "            elif num_params >= 15000 and num_params < 40000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1100'][1])\n",
    "            elif num_params >= 40000 and num_params < 70000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1100'][2])\n",
    "            elif num_params >= 70000 and num_params < 100000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1100'][3])\n",
    "            elif num_params >= 100000 and num_params < 150000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1100'][4])\n",
    "            elif num_params >= 150000 and num_params < 200000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1100'][5])\n",
    "            else:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1100'][6])\n",
    "        else:\n",
    "            if num_params < 15000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1200'][0])\n",
    "            elif num_params >= 15000 and num_params < 40000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1200'][1])\n",
    "            elif num_params >= 40000 and num_params < 70000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1200'][2])\n",
    "            elif num_params >= 70000 and num_params < 100000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1200'][3])\n",
    "            elif num_params >= 100000 and num_params < 150000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1200'][4])\n",
    "            elif num_params >= 150000 and num_params < 200000:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1200'][5])\n",
    "            else:\n",
    "                prune.l1_unstructured(module, name='weight', amount=prune_ratio_dict['1200'][6])\n",
    "print(\"[+] Pruning completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Total Params:  5784828  number of weights pruned:  2185495  percent pruned:  37.779774956143896\n"
     ]
    }
   ],
   "source": [
    "total_params, pruned_params, prune_ratio = find_unstructured_prune_ratio(pose_classification_pytorch_model)\n",
    "print(\"[+] Total Params: \", total_params, \" number of weights pruned: \", pruned_params, \" percent pruned: \", prune_ratio * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the performance of the pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Validation Batch No: 1 done. Percent Completion: 1.4492753623188406\n",
      "[+] Validation Batch No: 2 done. Percent Completion: 2.898550724637681\n",
      "[+] Validation Batch No: 3 done. Percent Completion: 4.3478260869565215\n",
      "[+] Validation Batch No: 4 done. Percent Completion: 5.797101449275362\n",
      "[+] Validation Batch No: 5 done. Percent Completion: 7.246376811594203\n",
      "[+] Validation Batch No: 6 done. Percent Completion: 8.695652173913043\n",
      "[+] Validation Batch No: 7 done. Percent Completion: 10.144927536231885\n",
      "[+] Validation Batch No: 8 done. Percent Completion: 11.594202898550725\n",
      "[+] Validation Batch No: 9 done. Percent Completion: 13.043478260869565\n",
      "[+] Validation Batch No: 10 done. Percent Completion: 14.492753623188406\n",
      "[+] Validation Batch No: 11 done. Percent Completion: 15.942028985507244\n",
      "[+] Validation Batch No: 12 done. Percent Completion: 17.391304347826086\n",
      "[+] Validation Batch No: 13 done. Percent Completion: 18.84057971014493\n",
      "[+] Validation Batch No: 14 done. Percent Completion: 20.28985507246377\n",
      "[+] Validation Batch No: 15 done. Percent Completion: 21.73913043478261\n",
      "[+] Validation Batch No: 16 done. Percent Completion: 23.18840579710145\n",
      "[+] Validation Batch No: 17 done. Percent Completion: 24.637681159420293\n",
      "[+] Validation Batch No: 18 done. Percent Completion: 26.08695652173913\n",
      "[+] Validation Batch No: 19 done. Percent Completion: 27.536231884057973\n",
      "[+] Validation Batch No: 20 done. Percent Completion: 28.985507246376812\n",
      "[+] Validation Batch No: 21 done. Percent Completion: 30.434782608695656\n",
      "[+] Validation Batch No: 22 done. Percent Completion: 31.88405797101449\n",
      "[+] Validation Batch No: 23 done. Percent Completion: 33.33333333333333\n",
      "[+] Validation Batch No: 24 done. Percent Completion: 34.78260869565217\n",
      "[+] Validation Batch No: 25 done. Percent Completion: 36.231884057971016\n",
      "[+] Validation Batch No: 26 done. Percent Completion: 37.68115942028986\n",
      "[+] Validation Batch No: 27 done. Percent Completion: 39.130434782608695\n",
      "[+] Validation Batch No: 28 done. Percent Completion: 40.57971014492754\n",
      "[+] Validation Batch No: 29 done. Percent Completion: 42.028985507246375\n",
      "[+] Validation Batch No: 30 done. Percent Completion: 43.47826086956522\n",
      "[+] Validation Batch No: 31 done. Percent Completion: 44.927536231884055\n",
      "[+] Validation Batch No: 32 done. Percent Completion: 46.3768115942029\n",
      "[+] Validation Batch No: 33 done. Percent Completion: 47.82608695652174\n",
      "[+] Validation Batch No: 34 done. Percent Completion: 49.275362318840585\n",
      "[+] Validation Batch No: 35 done. Percent Completion: 50.72463768115942\n",
      "[+] Validation Batch No: 36 done. Percent Completion: 52.17391304347826\n",
      "[+] Validation Batch No: 37 done. Percent Completion: 53.62318840579711\n",
      "[+] Validation Batch No: 38 done. Percent Completion: 55.072463768115945\n",
      "[+] Validation Batch No: 39 done. Percent Completion: 56.52173913043478\n",
      "[+] Validation Batch No: 40 done. Percent Completion: 57.971014492753625\n",
      "[+] Validation Batch No: 41 done. Percent Completion: 59.42028985507246\n",
      "[+] Validation Batch No: 42 done. Percent Completion: 60.86956521739131\n",
      "[+] Validation Batch No: 43 done. Percent Completion: 62.31884057971014\n",
      "[+] Validation Batch No: 44 done. Percent Completion: 63.76811594202898\n",
      "[+] Validation Batch No: 45 done. Percent Completion: 65.21739130434783\n",
      "[+] Validation Batch No: 46 done. Percent Completion: 66.66666666666666\n",
      "[+] Validation Batch No: 47 done. Percent Completion: 68.11594202898551\n",
      "[+] Validation Batch No: 48 done. Percent Completion: 69.56521739130434\n",
      "[+] Validation Batch No: 49 done. Percent Completion: 71.01449275362319\n",
      "[+] Validation Batch No: 50 done. Percent Completion: 72.46376811594203\n",
      "[+] Validation Batch No: 51 done. Percent Completion: 73.91304347826086\n",
      "[+] Validation Batch No: 52 done. Percent Completion: 75.36231884057972\n",
      "[+] Validation Batch No: 53 done. Percent Completion: 76.81159420289855\n",
      "[+] Validation Batch No: 54 done. Percent Completion: 78.26086956521739\n",
      "[+] Validation Batch No: 55 done. Percent Completion: 79.71014492753623\n",
      "[+] Validation Batch No: 56 done. Percent Completion: 81.15942028985508\n",
      "[+] Validation Batch No: 57 done. Percent Completion: 82.6086956521739\n",
      "[+] Validation Batch No: 58 done. Percent Completion: 84.05797101449275\n",
      "[+] Validation Batch No: 59 done. Percent Completion: 85.5072463768116\n",
      "[+] Validation Batch No: 60 done. Percent Completion: 86.95652173913044\n",
      "[+] Validation Batch No: 61 done. Percent Completion: 88.40579710144928\n",
      "[+] Validation Batch No: 62 done. Percent Completion: 89.85507246376811\n",
      "[+] Validation Batch No: 63 done. Percent Completion: 91.30434782608695\n",
      "[+] Validation Batch No: 64 done. Percent Completion: 92.7536231884058\n",
      "[+] Validation Batch No: 65 done. Percent Completion: 94.20289855072464\n",
      "[+] Validation Batch No: 66 done. Percent Completion: 95.65217391304348\n",
      "[+] Validation Batch No: 67 done. Percent Completion: 97.10144927536231\n",
      "[+] Validation Batch No: 68 done. Percent Completion: 98.55072463768117\n",
      "[+] Validation Batch No: 69 done. Percent Completion: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 11:19:52.946674: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "accuracy = validate_model(pose_classification_pytorch_model, val_dataset, total_batches_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Accuracy of pruned model: 50.36563071297989\n"
     ]
    }
   ],
   "source": [
    "print(f\"[+] Accuracy of pruned model: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can that due to pruning the accuracy has dropped from 61.24% to 50.36%. Now we'll fine-tune the pruned-model(pruning aware training) for small number of epochs=2, to recover the lost accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune the pruned model to recover the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 11:42:04.737478: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:6: Filling up shuffle buffer (this may take a while): 2486 of 2528\n",
      "2024-04-18 11:42:04.975499: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
      "2024-04-18 11:42:17.623993: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Total Batches in train dataset 158\n"
     ]
    }
   ],
   "source": [
    "total_batches_train = len(list(train_dataset))\n",
    "print(f\"[+] Total Batches in train dataset {total_batches_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Total Batches in train dataset 158\n"
     ]
    }
   ],
   "source": [
    "print(f\"[+] Total Batches in train dataset {total_batches_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utilities.data_loader_torch import CustomPyTorchDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have used Adam optimizer with a very small learninig rate, lr=1e-5 since we want our pruned model to smoothly adjust its params, this done so that the weights that were zeroed out due to pruning remain zero and we can smoothly recover the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataset, val_dataset, total_batches_train, total_batches_val, epochs=4, lr=1e-5, threshold=0.3):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        batch_count_train = 0\n",
    "\n",
    "        for batch in train_dataset:\n",
    "            inputs = (torch.from_numpy(batch[0].numpy())).to('mps')\n",
    "            labels = (torch.from_numpy(batch[1].numpy())).to('mps')\n",
    "            \n",
    "            optimizer.zero_grad() # to zero out the gradients after each batch is processed\n",
    "            batch_loss = 0.0\n",
    "            \n",
    "            for i in range(len(labels)):\n",
    "                feed_input = inputs[i].unsqueeze(0)  \n",
    "                feed_label = labels[i].unsqueeze(0).long()\n",
    "\n",
    "                output = model(feed_input)\n",
    "                \n",
    "                loss = criterion(output, feed_label)\n",
    "                batch_loss += loss\n",
    "\n",
    "            batch_count_train = batch_count_train + 1\n",
    "            # Backpropagation and parameter update after processing the whole batch\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += batch_loss.item() / len(labels)  # Average loss per sample\n",
    "            print(f\"[+] Training Batch No: {batch_count_train}. Percent completion {(batch_count_train / total_batches_train) * 100}\")\n",
    "        print(f\"[+] Epoch: {epoch+1}, Loss: {running_loss / total_batches_train}\")\n",
    "\n",
    "        total_params, pruned_params, prune_ratio = find_unstructured_prune_ratio(pose_classification_pytorch_model)\n",
    "        print(\"[+] Currently total Params: \", total_params, \" number of weights pruned: \", pruned_params, \" percent pruned: \", prune_ratio * 100)\n",
    "        \n",
    "        if prune_ratio < threshold:\n",
    "            print(\"[+] Pruning threshold limit reached. Exiting\")\n",
    "            break\n",
    "        if (epoch % 2 == 0):\n",
    "            val_accuracy = validate_model(pose_classification_pytorch_model, val_dataset, total_batches_val)\n",
    "            print(f\"[+] Epoch: {epoch + 1}, val-accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Training Batch No: 1. Percent completion 0.6329113924050633\n",
      "[+] Training Batch No: 2. Percent completion 1.2658227848101267\n",
      "[+] Training Batch No: 3. Percent completion 1.89873417721519\n",
      "[+] Training Batch No: 4. Percent completion 2.5316455696202533\n",
      "[+] Training Batch No: 5. Percent completion 3.1645569620253164\n",
      "[+] Training Batch No: 6. Percent completion 3.79746835443038\n",
      "[+] Training Batch No: 7. Percent completion 4.430379746835443\n",
      "[+] Training Batch No: 8. Percent completion 5.063291139240507\n",
      "[+] Training Batch No: 9. Percent completion 5.69620253164557\n",
      "[+] Training Batch No: 10. Percent completion 6.329113924050633\n",
      "[+] Training Batch No: 11. Percent completion 6.962025316455696\n",
      "[+] Training Batch No: 12. Percent completion 7.59493670886076\n",
      "[+] Training Batch No: 13. Percent completion 8.227848101265822\n",
      "[+] Training Batch No: 14. Percent completion 8.860759493670885\n",
      "[+] Training Batch No: 15. Percent completion 9.49367088607595\n",
      "[+] Training Batch No: 16. Percent completion 10.126582278481013\n",
      "[+] Training Batch No: 17. Percent completion 10.759493670886076\n",
      "[+] Training Batch No: 18. Percent completion 11.39240506329114\n",
      "[+] Training Batch No: 19. Percent completion 12.025316455696203\n",
      "[+] Training Batch No: 20. Percent completion 12.658227848101266\n",
      "[+] Training Batch No: 21. Percent completion 13.291139240506327\n",
      "[+] Training Batch No: 22. Percent completion 13.924050632911392\n",
      "[+] Training Batch No: 23. Percent completion 14.556962025316455\n",
      "[+] Training Batch No: 24. Percent completion 15.18987341772152\n",
      "[+] Training Batch No: 25. Percent completion 15.822784810126583\n",
      "[+] Training Batch No: 26. Percent completion 16.455696202531644\n",
      "[+] Training Batch No: 27. Percent completion 17.088607594936708\n",
      "[+] Training Batch No: 28. Percent completion 17.72151898734177\n",
      "[+] Training Batch No: 29. Percent completion 18.354430379746837\n",
      "[+] Training Batch No: 30. Percent completion 18.9873417721519\n",
      "[+] Training Batch No: 31. Percent completion 19.62025316455696\n",
      "[+] Training Batch No: 32. Percent completion 20.253164556962027\n",
      "[+] Training Batch No: 33. Percent completion 20.88607594936709\n",
      "[+] Training Batch No: 34. Percent completion 21.518987341772153\n",
      "[+] Training Batch No: 35. Percent completion 22.151898734177212\n",
      "[+] Training Batch No: 36. Percent completion 22.78481012658228\n",
      "[+] Training Batch No: 37. Percent completion 23.417721518987342\n",
      "[+] Training Batch No: 38. Percent completion 24.050632911392405\n",
      "[+] Training Batch No: 39. Percent completion 24.68354430379747\n",
      "[+] Training Batch No: 40. Percent completion 25.31645569620253\n",
      "[+] Training Batch No: 41. Percent completion 25.949367088607595\n",
      "[+] Training Batch No: 42. Percent completion 26.582278481012654\n",
      "[+] Training Batch No: 43. Percent completion 27.21518987341772\n",
      "[+] Training Batch No: 44. Percent completion 27.848101265822784\n",
      "[+] Training Batch No: 45. Percent completion 28.48101265822785\n",
      "[+] Training Batch No: 46. Percent completion 29.11392405063291\n",
      "[+] Training Batch No: 47. Percent completion 29.746835443037973\n",
      "[+] Training Batch No: 48. Percent completion 30.37974683544304\n",
      "[+] Training Batch No: 49. Percent completion 31.0126582278481\n",
      "[+] Training Batch No: 50. Percent completion 31.645569620253166\n",
      "[+] Training Batch No: 51. Percent completion 32.278481012658226\n",
      "[+] Training Batch No: 52. Percent completion 32.91139240506329\n",
      "[+] Training Batch No: 53. Percent completion 33.54430379746836\n",
      "[+] Training Batch No: 54. Percent completion 34.177215189873415\n",
      "[+] Training Batch No: 55. Percent completion 34.810126582278485\n",
      "[+] Training Batch No: 56. Percent completion 35.44303797468354\n",
      "[+] Training Batch No: 57. Percent completion 36.075949367088604\n",
      "[+] Training Batch No: 58. Percent completion 36.708860759493675\n",
      "[+] Training Batch No: 59. Percent completion 37.34177215189873\n",
      "[+] Training Batch No: 60. Percent completion 37.9746835443038\n",
      "[+] Training Batch No: 61. Percent completion 38.607594936708864\n",
      "[+] Training Batch No: 62. Percent completion 39.24050632911392\n",
      "[+] Training Batch No: 63. Percent completion 39.87341772151899\n",
      "[+] Training Batch No: 64. Percent completion 40.50632911392405\n",
      "[+] Training Batch No: 65. Percent completion 41.139240506329116\n",
      "[+] Training Batch No: 66. Percent completion 41.77215189873418\n",
      "[+] Training Batch No: 67. Percent completion 42.405063291139236\n",
      "[+] Training Batch No: 68. Percent completion 43.037974683544306\n",
      "[+] Training Batch No: 69. Percent completion 43.67088607594937\n",
      "[+] Training Batch No: 70. Percent completion 44.303797468354425\n",
      "[+] Training Batch No: 71. Percent completion 44.936708860759495\n",
      "[+] Training Batch No: 72. Percent completion 45.56962025316456\n",
      "[+] Training Batch No: 73. Percent completion 46.20253164556962\n",
      "[+] Training Batch No: 74. Percent completion 46.835443037974684\n",
      "[+] Training Batch No: 75. Percent completion 47.46835443037975\n",
      "[+] Training Batch No: 76. Percent completion 48.10126582278481\n",
      "[+] Training Batch No: 77. Percent completion 48.734177215189874\n",
      "[+] Training Batch No: 78. Percent completion 49.36708860759494\n",
      "[+] Training Batch No: 79. Percent completion 50.0\n",
      "[+] Training Batch No: 80. Percent completion 50.63291139240506\n",
      "[+] Training Batch No: 81. Percent completion 51.26582278481012\n",
      "[+] Training Batch No: 82. Percent completion 51.89873417721519\n",
      "[+] Training Batch No: 83. Percent completion 52.53164556962025\n",
      "[+] Training Batch No: 84. Percent completion 53.16455696202531\n",
      "[+] Training Batch No: 85. Percent completion 53.79746835443038\n",
      "[+] Training Batch No: 86. Percent completion 54.43037974683544\n",
      "[+] Training Batch No: 87. Percent completion 55.06329113924051\n",
      "[+] Training Batch No: 88. Percent completion 55.69620253164557\n",
      "[+] Training Batch No: 89. Percent completion 56.32911392405063\n",
      "[+] Training Batch No: 90. Percent completion 56.9620253164557\n",
      "[+] Training Batch No: 91. Percent completion 57.59493670886076\n",
      "[+] Training Batch No: 92. Percent completion 58.22784810126582\n",
      "[+] Training Batch No: 93. Percent completion 58.86075949367089\n",
      "[+] Training Batch No: 94. Percent completion 59.49367088607595\n",
      "[+] Training Batch No: 95. Percent completion 60.12658227848101\n",
      "[+] Training Batch No: 96. Percent completion 60.75949367088608\n",
      "[+] Training Batch No: 97. Percent completion 61.39240506329114\n",
      "[+] Training Batch No: 98. Percent completion 62.0253164556962\n",
      "[+] Training Batch No: 99. Percent completion 62.65822784810127\n",
      "[+] Training Batch No: 100. Percent completion 63.29113924050633\n",
      "[+] Training Batch No: 101. Percent completion 63.92405063291139\n",
      "[+] Training Batch No: 102. Percent completion 64.55696202531645\n",
      "[+] Training Batch No: 103. Percent completion 65.18987341772153\n",
      "[+] Training Batch No: 104. Percent completion 65.82278481012658\n",
      "[+] Training Batch No: 105. Percent completion 66.45569620253164\n",
      "[+] Training Batch No: 106. Percent completion 67.08860759493672\n",
      "[+] Training Batch No: 107. Percent completion 67.72151898734177\n",
      "[+] Training Batch No: 108. Percent completion 68.35443037974683\n",
      "[+] Training Batch No: 109. Percent completion 68.9873417721519\n",
      "[+] Training Batch No: 110. Percent completion 69.62025316455697\n",
      "[+] Training Batch No: 111. Percent completion 70.25316455696202\n",
      "[+] Training Batch No: 112. Percent completion 70.88607594936708\n",
      "[+] Training Batch No: 113. Percent completion 71.51898734177216\n",
      "[+] Training Batch No: 114. Percent completion 72.15189873417721\n",
      "[+] Training Batch No: 115. Percent completion 72.78481012658227\n",
      "[+] Training Batch No: 116. Percent completion 73.41772151898735\n",
      "[+] Training Batch No: 117. Percent completion 74.0506329113924\n",
      "[+] Training Batch No: 118. Percent completion 74.68354430379746\n",
      "[+] Training Batch No: 119. Percent completion 75.31645569620254\n",
      "[+] Training Batch No: 120. Percent completion 75.9493670886076\n",
      "[+] Training Batch No: 121. Percent completion 76.58227848101265\n",
      "[+] Training Batch No: 122. Percent completion 77.21518987341773\n",
      "[+] Training Batch No: 123. Percent completion 77.84810126582279\n",
      "[+] Training Batch No: 124. Percent completion 78.48101265822784\n",
      "[+] Training Batch No: 125. Percent completion 79.11392405063292\n",
      "[+] Training Batch No: 126. Percent completion 79.74683544303798\n",
      "[+] Training Batch No: 127. Percent completion 80.37974683544303\n",
      "[+] Training Batch No: 128. Percent completion 81.0126582278481\n",
      "[+] Training Batch No: 129. Percent completion 81.64556962025317\n",
      "[+] Training Batch No: 130. Percent completion 82.27848101265823\n",
      "[+] Training Batch No: 131. Percent completion 82.91139240506328\n",
      "[+] Training Batch No: 132. Percent completion 83.54430379746836\n",
      "[+] Training Batch No: 133. Percent completion 84.17721518987342\n",
      "[+] Training Batch No: 134. Percent completion 84.81012658227847\n",
      "[+] Training Batch No: 135. Percent completion 85.44303797468355\n",
      "[+] Training Batch No: 136. Percent completion 86.07594936708861\n",
      "[+] Training Batch No: 137. Percent completion 86.70886075949366\n",
      "[+] Training Batch No: 138. Percent completion 87.34177215189874\n",
      "[+] Training Batch No: 139. Percent completion 87.9746835443038\n",
      "[+] Training Batch No: 140. Percent completion 88.60759493670885\n",
      "[+] Training Batch No: 141. Percent completion 89.24050632911393\n",
      "[+] Training Batch No: 142. Percent completion 89.87341772151899\n",
      "[+] Training Batch No: 143. Percent completion 90.50632911392405\n",
      "[+] Training Batch No: 144. Percent completion 91.13924050632912\n",
      "[+] Training Batch No: 145. Percent completion 91.77215189873418\n",
      "[+] Training Batch No: 146. Percent completion 92.40506329113924\n",
      "[+] Training Batch No: 147. Percent completion 93.0379746835443\n",
      "[+] Training Batch No: 148. Percent completion 93.67088607594937\n",
      "[+] Training Batch No: 149. Percent completion 94.30379746835443\n",
      "[+] Training Batch No: 150. Percent completion 94.9367088607595\n",
      "[+] Training Batch No: 151. Percent completion 95.56962025316456\n",
      "[+] Training Batch No: 152. Percent completion 96.20253164556962\n",
      "[+] Training Batch No: 153. Percent completion 96.83544303797468\n",
      "[+] Training Batch No: 154. Percent completion 97.46835443037975\n",
      "[+] Training Batch No: 155. Percent completion 98.10126582278481\n",
      "[+] Training Batch No: 156. Percent completion 98.73417721518987\n",
      "[+] Training Batch No: 157. Percent completion 99.36708860759494\n",
      "[+] Training Batch No: 158. Percent completion 100.0\n",
      "[+] Epoch: 1, Loss: 2.453704627254341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 11:58:22.552703: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Currently total Params:  5784828  number of weights pruned:  2185495  percent pruned:  37.779774956143896\n",
      "[+] Validation Batch No: 1 done. Percent Completion: 1.4492753623188406\n",
      "[+] Validation Batch No: 2 done. Percent Completion: 2.898550724637681\n",
      "[+] Validation Batch No: 3 done. Percent Completion: 4.3478260869565215\n",
      "[+] Validation Batch No: 4 done. Percent Completion: 5.797101449275362\n",
      "[+] Validation Batch No: 5 done. Percent Completion: 7.246376811594203\n",
      "[+] Validation Batch No: 6 done. Percent Completion: 8.695652173913043\n",
      "[+] Validation Batch No: 7 done. Percent Completion: 10.144927536231885\n",
      "[+] Validation Batch No: 8 done. Percent Completion: 11.594202898550725\n",
      "[+] Validation Batch No: 9 done. Percent Completion: 13.043478260869565\n",
      "[+] Validation Batch No: 10 done. Percent Completion: 14.492753623188406\n",
      "[+] Validation Batch No: 11 done. Percent Completion: 15.942028985507244\n",
      "[+] Validation Batch No: 12 done. Percent Completion: 17.391304347826086\n",
      "[+] Validation Batch No: 13 done. Percent Completion: 18.84057971014493\n",
      "[+] Validation Batch No: 14 done. Percent Completion: 20.28985507246377\n",
      "[+] Validation Batch No: 15 done. Percent Completion: 21.73913043478261\n",
      "[+] Validation Batch No: 16 done. Percent Completion: 23.18840579710145\n",
      "[+] Validation Batch No: 17 done. Percent Completion: 24.637681159420293\n",
      "[+] Validation Batch No: 18 done. Percent Completion: 26.08695652173913\n",
      "[+] Validation Batch No: 19 done. Percent Completion: 27.536231884057973\n",
      "[+] Validation Batch No: 20 done. Percent Completion: 28.985507246376812\n",
      "[+] Validation Batch No: 21 done. Percent Completion: 30.434782608695656\n",
      "[+] Validation Batch No: 22 done. Percent Completion: 31.88405797101449\n",
      "[+] Validation Batch No: 23 done. Percent Completion: 33.33333333333333\n",
      "[+] Validation Batch No: 24 done. Percent Completion: 34.78260869565217\n",
      "[+] Validation Batch No: 25 done. Percent Completion: 36.231884057971016\n",
      "[+] Validation Batch No: 26 done. Percent Completion: 37.68115942028986\n",
      "[+] Validation Batch No: 27 done. Percent Completion: 39.130434782608695\n",
      "[+] Validation Batch No: 28 done. Percent Completion: 40.57971014492754\n",
      "[+] Validation Batch No: 29 done. Percent Completion: 42.028985507246375\n",
      "[+] Validation Batch No: 30 done. Percent Completion: 43.47826086956522\n",
      "[+] Validation Batch No: 31 done. Percent Completion: 44.927536231884055\n",
      "[+] Validation Batch No: 32 done. Percent Completion: 46.3768115942029\n",
      "[+] Validation Batch No: 33 done. Percent Completion: 47.82608695652174\n",
      "[+] Validation Batch No: 34 done. Percent Completion: 49.275362318840585\n",
      "[+] Validation Batch No: 35 done. Percent Completion: 50.72463768115942\n",
      "[+] Validation Batch No: 36 done. Percent Completion: 52.17391304347826\n",
      "[+] Validation Batch No: 37 done. Percent Completion: 53.62318840579711\n",
      "[+] Validation Batch No: 38 done. Percent Completion: 55.072463768115945\n",
      "[+] Validation Batch No: 39 done. Percent Completion: 56.52173913043478\n",
      "[+] Validation Batch No: 40 done. Percent Completion: 57.971014492753625\n",
      "[+] Validation Batch No: 41 done. Percent Completion: 59.42028985507246\n",
      "[+] Validation Batch No: 42 done. Percent Completion: 60.86956521739131\n",
      "[+] Validation Batch No: 43 done. Percent Completion: 62.31884057971014\n",
      "[+] Validation Batch No: 44 done. Percent Completion: 63.76811594202898\n",
      "[+] Validation Batch No: 45 done. Percent Completion: 65.21739130434783\n",
      "[+] Validation Batch No: 46 done. Percent Completion: 66.66666666666666\n",
      "[+] Validation Batch No: 47 done. Percent Completion: 68.11594202898551\n",
      "[+] Validation Batch No: 48 done. Percent Completion: 69.56521739130434\n",
      "[+] Validation Batch No: 49 done. Percent Completion: 71.01449275362319\n",
      "[+] Validation Batch No: 50 done. Percent Completion: 72.46376811594203\n",
      "[+] Validation Batch No: 51 done. Percent Completion: 73.91304347826086\n",
      "[+] Validation Batch No: 52 done. Percent Completion: 75.36231884057972\n",
      "[+] Validation Batch No: 53 done. Percent Completion: 76.81159420289855\n",
      "[+] Validation Batch No: 54 done. Percent Completion: 78.26086956521739\n",
      "[+] Validation Batch No: 55 done. Percent Completion: 79.71014492753623\n",
      "[+] Validation Batch No: 56 done. Percent Completion: 81.15942028985508\n",
      "[+] Validation Batch No: 57 done. Percent Completion: 82.6086956521739\n",
      "[+] Validation Batch No: 58 done. Percent Completion: 84.05797101449275\n",
      "[+] Validation Batch No: 59 done. Percent Completion: 85.5072463768116\n",
      "[+] Validation Batch No: 60 done. Percent Completion: 86.95652173913044\n",
      "[+] Validation Batch No: 61 done. Percent Completion: 88.40579710144928\n",
      "[+] Validation Batch No: 62 done. Percent Completion: 89.85507246376811\n",
      "[+] Validation Batch No: 63 done. Percent Completion: 91.30434782608695\n",
      "[+] Validation Batch No: 64 done. Percent Completion: 92.7536231884058\n",
      "[+] Validation Batch No: 65 done. Percent Completion: 94.20289855072464\n",
      "[+] Validation Batch No: 66 done. Percent Completion: 95.65217391304348\n",
      "[+] Validation Batch No: 67 done. Percent Completion: 97.10144927536231\n",
      "[+] Validation Batch No: 68 done. Percent Completion: 98.55072463768117\n",
      "[+] Validation Batch No: 69 done. Percent Completion: 100.0\n",
      "[+] Epoch: 1, val-accuracy: 58.40950639853748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 12:01:22.123645: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-18 12:01:32.147252: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:6: Filling up shuffle buffer (this may take a while): 1899 of 2528\n",
      "2024-04-18 12:01:35.615330: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Training Batch No: 1. Percent completion 0.6329113924050633\n",
      "[+] Training Batch No: 2. Percent completion 1.2658227848101267\n",
      "[+] Training Batch No: 3. Percent completion 1.89873417721519\n",
      "[+] Training Batch No: 4. Percent completion 2.5316455696202533\n",
      "[+] Training Batch No: 5. Percent completion 3.1645569620253164\n",
      "[+] Training Batch No: 6. Percent completion 3.79746835443038\n",
      "[+] Training Batch No: 7. Percent completion 4.430379746835443\n",
      "[+] Training Batch No: 8. Percent completion 5.063291139240507\n",
      "[+] Training Batch No: 9. Percent completion 5.69620253164557\n",
      "[+] Training Batch No: 10. Percent completion 6.329113924050633\n",
      "[+] Training Batch No: 11. Percent completion 6.962025316455696\n",
      "[+] Training Batch No: 12. Percent completion 7.59493670886076\n",
      "[+] Training Batch No: 13. Percent completion 8.227848101265822\n",
      "[+] Training Batch No: 14. Percent completion 8.860759493670885\n",
      "[+] Training Batch No: 15. Percent completion 9.49367088607595\n",
      "[+] Training Batch No: 16. Percent completion 10.126582278481013\n",
      "[+] Training Batch No: 17. Percent completion 10.759493670886076\n",
      "[+] Training Batch No: 18. Percent completion 11.39240506329114\n",
      "[+] Training Batch No: 19. Percent completion 12.025316455696203\n",
      "[+] Training Batch No: 20. Percent completion 12.658227848101266\n",
      "[+] Training Batch No: 21. Percent completion 13.291139240506327\n",
      "[+] Training Batch No: 22. Percent completion 13.924050632911392\n",
      "[+] Training Batch No: 23. Percent completion 14.556962025316455\n",
      "[+] Training Batch No: 24. Percent completion 15.18987341772152\n",
      "[+] Training Batch No: 25. Percent completion 15.822784810126583\n",
      "[+] Training Batch No: 26. Percent completion 16.455696202531644\n",
      "[+] Training Batch No: 27. Percent completion 17.088607594936708\n",
      "[+] Training Batch No: 28. Percent completion 17.72151898734177\n",
      "[+] Training Batch No: 29. Percent completion 18.354430379746837\n",
      "[+] Training Batch No: 30. Percent completion 18.9873417721519\n",
      "[+] Training Batch No: 31. Percent completion 19.62025316455696\n",
      "[+] Training Batch No: 32. Percent completion 20.253164556962027\n",
      "[+] Training Batch No: 33. Percent completion 20.88607594936709\n",
      "[+] Training Batch No: 34. Percent completion 21.518987341772153\n",
      "[+] Training Batch No: 35. Percent completion 22.151898734177212\n",
      "[+] Training Batch No: 36. Percent completion 22.78481012658228\n",
      "[+] Training Batch No: 37. Percent completion 23.417721518987342\n",
      "[+] Training Batch No: 38. Percent completion 24.050632911392405\n",
      "[+] Training Batch No: 39. Percent completion 24.68354430379747\n",
      "[+] Training Batch No: 40. Percent completion 25.31645569620253\n",
      "[+] Training Batch No: 41. Percent completion 25.949367088607595\n",
      "[+] Training Batch No: 42. Percent completion 26.582278481012654\n",
      "[+] Training Batch No: 43. Percent completion 27.21518987341772\n",
      "[+] Training Batch No: 44. Percent completion 27.848101265822784\n",
      "[+] Training Batch No: 45. Percent completion 28.48101265822785\n",
      "[+] Training Batch No: 46. Percent completion 29.11392405063291\n",
      "[+] Training Batch No: 47. Percent completion 29.746835443037973\n",
      "[+] Training Batch No: 48. Percent completion 30.37974683544304\n",
      "[+] Training Batch No: 49. Percent completion 31.0126582278481\n",
      "[+] Training Batch No: 50. Percent completion 31.645569620253166\n",
      "[+] Training Batch No: 51. Percent completion 32.278481012658226\n",
      "[+] Training Batch No: 52. Percent completion 32.91139240506329\n",
      "[+] Training Batch No: 53. Percent completion 33.54430379746836\n",
      "[+] Training Batch No: 54. Percent completion 34.177215189873415\n",
      "[+] Training Batch No: 55. Percent completion 34.810126582278485\n",
      "[+] Training Batch No: 56. Percent completion 35.44303797468354\n",
      "[+] Training Batch No: 57. Percent completion 36.075949367088604\n",
      "[+] Training Batch No: 58. Percent completion 36.708860759493675\n",
      "[+] Training Batch No: 59. Percent completion 37.34177215189873\n",
      "[+] Training Batch No: 60. Percent completion 37.9746835443038\n",
      "[+] Training Batch No: 61. Percent completion 38.607594936708864\n",
      "[+] Training Batch No: 62. Percent completion 39.24050632911392\n",
      "[+] Training Batch No: 63. Percent completion 39.87341772151899\n",
      "[+] Training Batch No: 64. Percent completion 40.50632911392405\n",
      "[+] Training Batch No: 65. Percent completion 41.139240506329116\n",
      "[+] Training Batch No: 66. Percent completion 41.77215189873418\n",
      "[+] Training Batch No: 67. Percent completion 42.405063291139236\n",
      "[+] Training Batch No: 68. Percent completion 43.037974683544306\n",
      "[+] Training Batch No: 69. Percent completion 43.67088607594937\n",
      "[+] Training Batch No: 70. Percent completion 44.303797468354425\n",
      "[+] Training Batch No: 71. Percent completion 44.936708860759495\n",
      "[+] Training Batch No: 72. Percent completion 45.56962025316456\n",
      "[+] Training Batch No: 73. Percent completion 46.20253164556962\n",
      "[+] Training Batch No: 74. Percent completion 46.835443037974684\n",
      "[+] Training Batch No: 75. Percent completion 47.46835443037975\n",
      "[+] Training Batch No: 76. Percent completion 48.10126582278481\n",
      "[+] Training Batch No: 77. Percent completion 48.734177215189874\n",
      "[+] Training Batch No: 78. Percent completion 49.36708860759494\n",
      "[+] Training Batch No: 79. Percent completion 50.0\n",
      "[+] Training Batch No: 80. Percent completion 50.63291139240506\n",
      "[+] Training Batch No: 81. Percent completion 51.26582278481012\n",
      "[+] Training Batch No: 82. Percent completion 51.89873417721519\n",
      "[+] Training Batch No: 83. Percent completion 52.53164556962025\n",
      "[+] Training Batch No: 84. Percent completion 53.16455696202531\n",
      "[+] Training Batch No: 85. Percent completion 53.79746835443038\n",
      "[+] Training Batch No: 86. Percent completion 54.43037974683544\n",
      "[+] Training Batch No: 87. Percent completion 55.06329113924051\n",
      "[+] Training Batch No: 88. Percent completion 55.69620253164557\n",
      "[+] Training Batch No: 89. Percent completion 56.32911392405063\n",
      "[+] Training Batch No: 90. Percent completion 56.9620253164557\n",
      "[+] Training Batch No: 91. Percent completion 57.59493670886076\n",
      "[+] Training Batch No: 92. Percent completion 58.22784810126582\n",
      "[+] Training Batch No: 93. Percent completion 58.86075949367089\n",
      "[+] Training Batch No: 94. Percent completion 59.49367088607595\n",
      "[+] Training Batch No: 95. Percent completion 60.12658227848101\n",
      "[+] Training Batch No: 96. Percent completion 60.75949367088608\n",
      "[+] Training Batch No: 97. Percent completion 61.39240506329114\n",
      "[+] Training Batch No: 98. Percent completion 62.0253164556962\n",
      "[+] Training Batch No: 99. Percent completion 62.65822784810127\n",
      "[+] Training Batch No: 100. Percent completion 63.29113924050633\n",
      "[+] Training Batch No: 101. Percent completion 63.92405063291139\n",
      "[+] Training Batch No: 102. Percent completion 64.55696202531645\n",
      "[+] Training Batch No: 103. Percent completion 65.18987341772153\n",
      "[+] Training Batch No: 104. Percent completion 65.82278481012658\n",
      "[+] Training Batch No: 105. Percent completion 66.45569620253164\n",
      "[+] Training Batch No: 106. Percent completion 67.08860759493672\n",
      "[+] Training Batch No: 107. Percent completion 67.72151898734177\n",
      "[+] Training Batch No: 108. Percent completion 68.35443037974683\n",
      "[+] Training Batch No: 109. Percent completion 68.9873417721519\n",
      "[+] Training Batch No: 110. Percent completion 69.62025316455697\n",
      "[+] Training Batch No: 111. Percent completion 70.25316455696202\n",
      "[+] Training Batch No: 112. Percent completion 70.88607594936708\n",
      "[+] Training Batch No: 113. Percent completion 71.51898734177216\n",
      "[+] Training Batch No: 114. Percent completion 72.15189873417721\n",
      "[+] Training Batch No: 115. Percent completion 72.78481012658227\n",
      "[+] Training Batch No: 116. Percent completion 73.41772151898735\n",
      "[+] Training Batch No: 117. Percent completion 74.0506329113924\n",
      "[+] Training Batch No: 118. Percent completion 74.68354430379746\n",
      "[+] Training Batch No: 119. Percent completion 75.31645569620254\n",
      "[+] Training Batch No: 120. Percent completion 75.9493670886076\n",
      "[+] Training Batch No: 121. Percent completion 76.58227848101265\n",
      "[+] Training Batch No: 122. Percent completion 77.21518987341773\n",
      "[+] Training Batch No: 123. Percent completion 77.84810126582279\n",
      "[+] Training Batch No: 124. Percent completion 78.48101265822784\n",
      "[+] Training Batch No: 125. Percent completion 79.11392405063292\n",
      "[+] Training Batch No: 126. Percent completion 79.74683544303798\n",
      "[+] Training Batch No: 127. Percent completion 80.37974683544303\n",
      "[+] Training Batch No: 128. Percent completion 81.0126582278481\n",
      "[+] Training Batch No: 129. Percent completion 81.64556962025317\n",
      "[+] Training Batch No: 130. Percent completion 82.27848101265823\n",
      "[+] Training Batch No: 131. Percent completion 82.91139240506328\n",
      "[+] Training Batch No: 132. Percent completion 83.54430379746836\n",
      "[+] Training Batch No: 133. Percent completion 84.17721518987342\n",
      "[+] Training Batch No: 134. Percent completion 84.81012658227847\n",
      "[+] Training Batch No: 135. Percent completion 85.44303797468355\n",
      "[+] Training Batch No: 136. Percent completion 86.07594936708861\n",
      "[+] Training Batch No: 137. Percent completion 86.70886075949366\n",
      "[+] Training Batch No: 138. Percent completion 87.34177215189874\n",
      "[+] Training Batch No: 139. Percent completion 87.9746835443038\n",
      "[+] Training Batch No: 140. Percent completion 88.60759493670885\n",
      "[+] Training Batch No: 141. Percent completion 89.24050632911393\n",
      "[+] Training Batch No: 142. Percent completion 89.87341772151899\n",
      "[+] Training Batch No: 143. Percent completion 90.50632911392405\n",
      "[+] Training Batch No: 144. Percent completion 91.13924050632912\n",
      "[+] Training Batch No: 145. Percent completion 91.77215189873418\n",
      "[+] Training Batch No: 146. Percent completion 92.40506329113924\n",
      "[+] Training Batch No: 147. Percent completion 93.0379746835443\n",
      "[+] Training Batch No: 148. Percent completion 93.67088607594937\n",
      "[+] Training Batch No: 149. Percent completion 94.30379746835443\n",
      "[+] Training Batch No: 150. Percent completion 94.9367088607595\n",
      "[+] Training Batch No: 151. Percent completion 95.56962025316456\n",
      "[+] Training Batch No: 152. Percent completion 96.20253164556962\n",
      "[+] Training Batch No: 153. Percent completion 96.83544303797468\n",
      "[+] Training Batch No: 154. Percent completion 97.46835443037975\n",
      "[+] Training Batch No: 155. Percent completion 98.10126582278481\n",
      "[+] Training Batch No: 156. Percent completion 98.73417721518987\n",
      "[+] Training Batch No: 157. Percent completion 99.36708860759494\n",
      "[+] Training Batch No: 158. Percent completion 100.0\n",
      "[+] Epoch: 2, Loss: 2.3399982527841496\n",
      "[+] Currently total Params:  5784828  number of weights pruned:  2185495  percent pruned:  37.779774956143896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 12:18:14.631135: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "train_model(pose_classification_pytorch_model, train_dataset, val_dataset, total_batches_train, total_batches_val, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Validation Batch No: 1 done. Percent Completion: 1.4492753623188406\n",
      "[+] Validation Batch No: 2 done. Percent Completion: 2.898550724637681\n",
      "[+] Validation Batch No: 3 done. Percent Completion: 4.3478260869565215\n",
      "[+] Validation Batch No: 4 done. Percent Completion: 5.797101449275362\n",
      "[+] Validation Batch No: 5 done. Percent Completion: 7.246376811594203\n",
      "[+] Validation Batch No: 6 done. Percent Completion: 8.695652173913043\n",
      "[+] Validation Batch No: 7 done. Percent Completion: 10.144927536231885\n",
      "[+] Validation Batch No: 8 done. Percent Completion: 11.594202898550725\n",
      "[+] Validation Batch No: 9 done. Percent Completion: 13.043478260869565\n",
      "[+] Validation Batch No: 10 done. Percent Completion: 14.492753623188406\n",
      "[+] Validation Batch No: 11 done. Percent Completion: 15.942028985507244\n",
      "[+] Validation Batch No: 12 done. Percent Completion: 17.391304347826086\n",
      "[+] Validation Batch No: 13 done. Percent Completion: 18.84057971014493\n",
      "[+] Validation Batch No: 14 done. Percent Completion: 20.28985507246377\n",
      "[+] Validation Batch No: 15 done. Percent Completion: 21.73913043478261\n",
      "[+] Validation Batch No: 16 done. Percent Completion: 23.18840579710145\n",
      "[+] Validation Batch No: 17 done. Percent Completion: 24.637681159420293\n",
      "[+] Validation Batch No: 18 done. Percent Completion: 26.08695652173913\n",
      "[+] Validation Batch No: 19 done. Percent Completion: 27.536231884057973\n",
      "[+] Validation Batch No: 20 done. Percent Completion: 28.985507246376812\n",
      "[+] Validation Batch No: 21 done. Percent Completion: 30.434782608695656\n",
      "[+] Validation Batch No: 22 done. Percent Completion: 31.88405797101449\n",
      "[+] Validation Batch No: 23 done. Percent Completion: 33.33333333333333\n",
      "[+] Validation Batch No: 24 done. Percent Completion: 34.78260869565217\n",
      "[+] Validation Batch No: 25 done. Percent Completion: 36.231884057971016\n",
      "[+] Validation Batch No: 26 done. Percent Completion: 37.68115942028986\n",
      "[+] Validation Batch No: 27 done. Percent Completion: 39.130434782608695\n",
      "[+] Validation Batch No: 28 done. Percent Completion: 40.57971014492754\n",
      "[+] Validation Batch No: 29 done. Percent Completion: 42.028985507246375\n",
      "[+] Validation Batch No: 30 done. Percent Completion: 43.47826086956522\n",
      "[+] Validation Batch No: 31 done. Percent Completion: 44.927536231884055\n",
      "[+] Validation Batch No: 32 done. Percent Completion: 46.3768115942029\n",
      "[+] Validation Batch No: 33 done. Percent Completion: 47.82608695652174\n",
      "[+] Validation Batch No: 34 done. Percent Completion: 49.275362318840585\n",
      "[+] Validation Batch No: 35 done. Percent Completion: 50.72463768115942\n",
      "[+] Validation Batch No: 36 done. Percent Completion: 52.17391304347826\n",
      "[+] Validation Batch No: 37 done. Percent Completion: 53.62318840579711\n",
      "[+] Validation Batch No: 38 done. Percent Completion: 55.072463768115945\n",
      "[+] Validation Batch No: 39 done. Percent Completion: 56.52173913043478\n",
      "[+] Validation Batch No: 40 done. Percent Completion: 57.971014492753625\n",
      "[+] Validation Batch No: 41 done. Percent Completion: 59.42028985507246\n",
      "[+] Validation Batch No: 42 done. Percent Completion: 60.86956521739131\n",
      "[+] Validation Batch No: 43 done. Percent Completion: 62.31884057971014\n",
      "[+] Validation Batch No: 44 done. Percent Completion: 63.76811594202898\n",
      "[+] Validation Batch No: 45 done. Percent Completion: 65.21739130434783\n",
      "[+] Validation Batch No: 46 done. Percent Completion: 66.66666666666666\n",
      "[+] Validation Batch No: 47 done. Percent Completion: 68.11594202898551\n",
      "[+] Validation Batch No: 48 done. Percent Completion: 69.56521739130434\n",
      "[+] Validation Batch No: 49 done. Percent Completion: 71.01449275362319\n",
      "[+] Validation Batch No: 50 done. Percent Completion: 72.46376811594203\n",
      "[+] Validation Batch No: 51 done. Percent Completion: 73.91304347826086\n",
      "[+] Validation Batch No: 52 done. Percent Completion: 75.36231884057972\n",
      "[+] Validation Batch No: 53 done. Percent Completion: 76.81159420289855\n",
      "[+] Validation Batch No: 54 done. Percent Completion: 78.26086956521739\n",
      "[+] Validation Batch No: 55 done. Percent Completion: 79.71014492753623\n",
      "[+] Validation Batch No: 56 done. Percent Completion: 81.15942028985508\n",
      "[+] Validation Batch No: 57 done. Percent Completion: 82.6086956521739\n",
      "[+] Validation Batch No: 58 done. Percent Completion: 84.05797101449275\n",
      "[+] Validation Batch No: 59 done. Percent Completion: 85.5072463768116\n",
      "[+] Validation Batch No: 60 done. Percent Completion: 86.95652173913044\n",
      "[+] Validation Batch No: 61 done. Percent Completion: 88.40579710144928\n",
      "[+] Validation Batch No: 62 done. Percent Completion: 89.85507246376811\n",
      "[+] Validation Batch No: 63 done. Percent Completion: 91.30434782608695\n",
      "[+] Validation Batch No: 64 done. Percent Completion: 92.7536231884058\n",
      "[+] Validation Batch No: 65 done. Percent Completion: 94.20289855072464\n",
      "[+] Validation Batch No: 66 done. Percent Completion: 95.65217391304348\n",
      "[+] Validation Batch No: 67 done. Percent Completion: 97.10144927536231\n",
      "[+] Validation Batch No: 68 done. Percent Completion: 98.55072463768117\n",
      "[+] Validation Batch No: 69 done. Percent Completion: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 12:21:12.985860: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "accuracy = validate_model(pose_classification_pytorch_model, val_dataset, total_batches_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Accuracy of fine-tuned pruned model:  61.608775137111515\n"
     ]
    }
   ],
   "source": [
    "print(\"[+] Accuracy of fine-tuned pruned model: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pose_classification_pytorch_model, './pruned_models/pruned_pose_classificaiton_model_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_model = torch.load('./pruned_models/pruned_pose_classificaiton_model_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Total Params:  5784828  number of weights pruned:  2185495  percent pruned:  37.779774956143896\n"
     ]
    }
   ],
   "source": [
    "total_params, pruned_params, prune_ratio = find_unstructured_prune_ratio(pose_model)\n",
    "print(\"[+] Total Params: \", total_params, \" number of weights pruned: \", pruned_params, \" percent pruned: \", prune_ratio * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning the pruned model for 2 epochs(pruning aware training) has allowed us to recover the accuracy from 50.36% to 62.24%, and the number of pruned params is the same as before since we used a very low lr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>This is just to see if that the weight matrices actually contain 0 weights and their mask is set to 0</h5>\n",
    "Basically the in pytorch even after pruning the original weights are stored as'weight_orig', instead we have a mask that shows if the weight is pruned or not. If mask=0(pruned) or we can directly use module.weight to see the pruned weights.<br>\n",
    "We will just print the starting 100 pruned weights, their mask and their original value before pruning only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Pruned weight found at:  (0, 2, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0019, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (0, 5, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0003, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (0, 11, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0017, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (0, 21, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0009, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (0, 24, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0013, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (0, 26, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0017, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (0, 86, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0012, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (0, 87, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0013, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (0, 93, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0015, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 4, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0013, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 5, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0006, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 7, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0003, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 9, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0018, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 12, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0019, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 19, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0006, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 20, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0002, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 22, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0018, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 24, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0014, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 29, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0008, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 33, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0002, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 36, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0004, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 47, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0002, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 48, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0008, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 55, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0007, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 56, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0002, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 60, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0005, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 68, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0002, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 70, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0017, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 72, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0004, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 78, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0006, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 80, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0006, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 89, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0016, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 90, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0006, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 93, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0003, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (1, 95, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0014, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 5, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0018, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 6, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0009, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 10, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(9.6779e-05, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 11, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0002, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 13, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0012, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 16, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0018, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 19, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0019, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 21, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0005, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 22, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0015, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 23, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0019, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 26, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0003, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 33, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0007, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 35, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0017, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 39, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0015, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 44, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0004, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 47, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0013, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 50, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0010, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 54, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0016, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 57, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0014, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 59, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(5.9540e-05, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 60, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0007, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 61, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0012, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 62, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0016, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 68, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0010, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 73, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0006, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 75, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(5.4101e-06, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 76, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0014, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 80, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0012, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 81, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0011, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 87, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0014, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (2, 92, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0007, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 5, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0018, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 11, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0019, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 12, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0002, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 13, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(2.2151e-05, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 15, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0015, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 20, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0002, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 23, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0005, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 25, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0009, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 30, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0015, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 32, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0003, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 35, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0017, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 43, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0012, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 47, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0016, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 48, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0011, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 49, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0011, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 50, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0013, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 51, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0004, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 53, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0001, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 65, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0007, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 72, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0006, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 75, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0017, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 78, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0018, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 92, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0017, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (3, 94, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0011, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (4, 1, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0011, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (4, 2, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0017, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (4, 12, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-1.0181e-05, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (4, 15, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0010, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (4, 22, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0009, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (4, 23, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0007, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (4, 24, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0010, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (4, 28, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0018, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (4, 31, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0005, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (4, 33, 0, 0)  val:  tensor(0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(0.0018, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "[+] Pruned weight found at:  (4, 35, 0, 0)  val:  tensor(-0., device='mps:0', grad_fn=<SelectBackward0>)\n",
      "[+] Mask:  tensor(0., device='mps:0')\n",
      "[+] Original weight value was:  tensor(-0.0011, device='mps:0', grad_fn=<SelectBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for name, module in pose_classification_pytorch_model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d) and hasattr(module, 'weight'):\n",
    "        if 'Conv_Conv' in name:\n",
    "            # print((list(module.named_parameters())[0])[1].shape)\n",
    "            layer_num = None\n",
    "            if (name[14] >= '0' and name[14] <= '9'):\n",
    "                layer_num = int(name[11:15])\n",
    "            else:\n",
    "                layer_num = int(name[11:14])\n",
    "            \n",
    "            if layer_num < 800: # layers that have layer_num < 800 are ignored\n",
    "                continue\n",
    "            \n",
    "            num_layer_params = module.weight.numel()\n",
    "            num_pruned_params = (module.weight == 0).sum().item()\n",
    "            weight_matrix = (list(module.named_parameters())[0][1])\n",
    "\n",
    "            orig_weight_matrix = None\n",
    "            if 'weight' in list(module.named_parameters())[0][0]:\n",
    "                orig_weight_matrix = list(module.named_parameters())[0][1]\n",
    "                \n",
    "            else:\n",
    "                orig_weight_matrix = list(module.named_parameters())[1][1]\n",
    "\n",
    "            \n",
    "            pruned_weights = (module.weight == 0)\n",
    "            weight_mask = list(module.named_buffers())[0][1]\n",
    "            \n",
    "            for i in range((pruned_weights.shape[0])):\n",
    "                for j in range((pruned_weights.shape[1])):\n",
    "                    for k in range((pruned_weights.shape[2])):\n",
    "                        for l in range((pruned_weights.shape[3])):\n",
    "                            \n",
    "                            if pruned_weights[i][j][k][l]:\n",
    "                                print(\"[+] Pruned weight found at: \", (i, j, k, l), \" val: \", module.weight[i][j][k][l])\n",
    "                                print(\"[+] Mask: \", weight_mask[i][j][k][l])\n",
    "                                print(\"[+] Original weight value was: \", orig_weight_matrix[i][j][k][l])\n",
    "                                print()\n",
    "                                count += 1\n",
    "                            if count > 100:\n",
    "                                break\n",
    "                        if count > 100:\n",
    "                                break\n",
    "                    if count > 100:\n",
    "                                break\n",
    "                if count > 100:\n",
    "                                break\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Now let's compress the original model and the pruned model and compare their compression ratios</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.utils import compress_file\n",
    "from utilities.utils import get_compressed_file_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File compressed successfully: ./compressed_models/pose_classification_torch.gz\n"
     ]
    }
   ],
   "source": [
    "compress_file('./pose_classification_model/pose_classificaiton_model_torch_0.pth', './compressed_models/pose_classification_torch.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File compressed successfully: ./compressed_models/pruned_pose_classification_torch.gz\n"
     ]
    }
   ],
   "source": [
    "compress_file('./pruned_models/pruned_pose_classificaiton_model_0.pth', './compressed_models/pruned_pose_classification_torch.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of compressed file './pose_classification_model/pose_classificaiton_model_torch_0.pth': 82597522 bytes\n",
      "Size of compressed file './pruned_models/pruned_pose_classificaiton_model_0.pth': 125443389 bytes\n",
      "Size of compressed file './compressed_models/pose_classification_torch.gz': 69856912 bytes\n",
      "Size of compressed file './compressed_models/pruned_pose_classification_torch.gz': 84404808 bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Orginial uncompressed: 82.597522 MB',\n",
       " 'Orginial compressed: 69.856912 MB',\n",
       " 'Pruned uncompressed: 125.443389 MB',\n",
       " 'Pruned compressed: 84.404808 MB')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_uncompressed_size, pruned_uncompressed_size = get_compressed_file_size('./pose_classification_model/pose_classificaiton_model_torch_0.pth'), get_compressed_file_size('./pruned_models/pruned_pose_classificaiton_model_0.pth')\n",
    "original_compressed_size, pruned_compressed_size = get_compressed_file_size('./compressed_models/pose_classification_torch.gz'), get_compressed_file_size('./compressed_models/pruned_pose_classification_torch.gz')\n",
    "f'Orginial uncompressed: {original_uncompressed_size / 1e6} MB', f'Orginial compressed: {original_compressed_size / 1e6} MB', f'Pruned uncompressed: {pruned_uncompressed_size / 1e6} MB', f'Pruned compressed: {pruned_compressed_size / 1e6} MB'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can that pruning has increased the size of the model because in pytorch when we prune the model it does not remove the original weights instead it adds a weight_mask where if value=0 means weight is pruned. Later in the notebook we remove the pruning metadata to reduce the file size.<br>\n",
    "We have shown this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_pose_model = torch.load('./pruned_models/pruned_pose_classificaiton_model_0.pth')\n",
    "unpruned_pose_model = torch.load('./pose_classification_model/pose_classificaiton_model_torch_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Number of weight mask layers:  0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for buffer in unpruned_pose_model.named_buffers():\n",
    "    if 'weight_mask' in buffer[0]:\n",
    "        print(buffer[0])\n",
    "        count += 1\n",
    "\n",
    "print(\"[+] Number of weight mask layers: \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_Conv__804:0.weight_mask\n",
      "Conv_Conv__820:0.weight_mask\n",
      "Conv_Conv__826:0.weight_mask\n",
      "Conv_Conv__828:0.weight_mask\n",
      "Conv_Conv__830:0.weight_mask\n",
      "Conv_Conv__846:0.weight_mask\n",
      "Conv_Conv__852:0.weight_mask\n",
      "Conv_Conv__854:0.weight_mask\n",
      "Conv_Conv__860:0.weight_mask\n",
      "Conv_Conv__876:0.weight_mask\n",
      "Conv_Conv__882:0.weight_mask\n",
      "Conv_Conv__884:0.weight_mask\n",
      "Conv_Conv__890:0.weight_mask\n",
      "Conv_Conv__906:0.weight_mask\n",
      "Conv_Conv__912:0.weight_mask\n",
      "Conv_Conv__914:0.weight_mask\n",
      "Conv_Conv__920:0.weight_mask\n",
      "Conv_Conv__936:0.weight_mask\n",
      "Conv_Conv__942:0.weight_mask\n",
      "Conv_Conv__944:0.weight_mask\n",
      "Conv_Conv__950:0.weight_mask\n",
      "Conv_Conv__966:0.weight_mask\n",
      "Conv_Conv__972:0.weight_mask\n",
      "Conv_Conv__974:0.weight_mask\n",
      "Conv_Conv__976:0.weight_mask\n",
      "Conv_Conv__992:0.weight_mask\n",
      "Conv_Conv__998:0.weight_mask\n",
      "Conv_Conv__1000:0.weight_mask\n",
      "Conv_Conv__1006:0.weight_mask\n",
      "Conv_Conv__1022:0.weight_mask\n",
      "Conv_Conv__1028:0.weight_mask\n",
      "Conv_Conv__1030:0.weight_mask\n",
      "Conv_Conv__1036:0.weight_mask\n",
      "Conv_Conv__1052:0.weight_mask\n",
      "Conv_Conv__1058:0.weight_mask\n",
      "Conv_Conv__1060:0.weight_mask\n",
      "Conv_Conv__1066:0.weight_mask\n",
      "Conv_Conv__1082:0.weight_mask\n",
      "Conv_Conv__1088:0.weight_mask\n",
      "Conv_Conv__1090:0.weight_mask\n",
      "Conv_Conv__1096:0.weight_mask\n",
      "Conv_Conv__1112:0.weight_mask\n",
      "Conv_Conv__1118:0.weight_mask\n",
      "Conv_Conv__1120:0.weight_mask\n",
      "Conv_Conv__1126:0.weight_mask\n",
      "Conv_Conv__1142:0.weight_mask\n",
      "Conv_Conv__1148:0.weight_mask\n",
      "Conv_Conv__1150:0.weight_mask\n",
      "Conv_Conv__1156:0.weight_mask\n",
      "Conv_Conv__1172:0.weight_mask\n",
      "Conv_Conv__1178:0.weight_mask\n",
      "Conv_Conv__1180:0.weight_mask\n",
      "Conv_Conv__1186:0.weight_mask\n",
      "Conv_Conv__1202:0.weight_mask\n",
      "Conv_Conv__1208:0.weight_mask\n",
      "Conv_Conv__1210:0.weight_mask\n",
      "Conv_Conv__1212:0.weight_mask\n",
      "\n",
      "[+] Number of weight mask layers:  57\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for buffer in pruned_pose_model.named_buffers():\n",
    "    if 'weight_mask' in buffer[0]:\n",
    "        print(buffer[0])\n",
    "        count += 1\n",
    "print()\n",
    "print(\"[+] Number of weight mask layers: \", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above that the pruned model has 57 weight mask layers containing lots of params, that's why the model size of pruned model is greater, but as we have shown above pruned models have better compression ratio than unpruned models making them ideal for downloading purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Original model compression ratio:  84.54473937224076  pruned model compression ratio:  67.28517833650046\n"
     ]
    }
   ],
   "source": [
    "compression_ratio_original = (original_compressed_size / original_uncompressed_size) * 100\n",
    "compression_ratio_pruned = (pruned_compressed_size / pruned_uncompressed_size) * 100\n",
    "print(\"[+] Original model compression ratio: \", compression_ratio_original, \" pruned model compression ratio: \", compression_ratio_pruned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the pruning metadata.<br>\n",
    "pruned.remove(): The pruned parameter named name remains permanently pruned, and the parameter named name+'_orig' is removed from the parameter list. Similarly, the buffer named name+'_mask' is removed from the buffers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Pruning info removed\n"
     ]
    }
   ],
   "source": [
    "for name, module in pruned_pose_model.named_modules():\n",
    "    if 'Conv_Conv' in name:\n",
    "        # print((list(module.named_parameters())[0])[1].shape)\n",
    "        layer_num = None\n",
    "        if (name[14] >= '0' and name[14] <= '9'):\n",
    "            layer_num = int(name[11:15])\n",
    "        else:\n",
    "            layer_num = int(name[11:14])\n",
    "        \n",
    "        if layer_num < 800: # layers that have layer_num < 800 are ignored\n",
    "            continue\n",
    "        \n",
    "        prune.remove(module, 'weight')\n",
    "print(\"[+] Pruning info removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 12:39:48.406734: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Validation Batch No: 1 done. Percent Completion: 1.4492753623188406\n",
      "[+] Validation Batch No: 2 done. Percent Completion: 2.898550724637681\n",
      "[+] Validation Batch No: 3 done. Percent Completion: 4.3478260869565215\n",
      "[+] Validation Batch No: 4 done. Percent Completion: 5.797101449275362\n",
      "[+] Validation Batch No: 5 done. Percent Completion: 7.246376811594203\n",
      "[+] Validation Batch No: 6 done. Percent Completion: 8.695652173913043\n",
      "[+] Validation Batch No: 7 done. Percent Completion: 10.144927536231885\n",
      "[+] Validation Batch No: 8 done. Percent Completion: 11.594202898550725\n",
      "[+] Validation Batch No: 9 done. Percent Completion: 13.043478260869565\n",
      "[+] Validation Batch No: 10 done. Percent Completion: 14.492753623188406\n",
      "[+] Validation Batch No: 11 done. Percent Completion: 15.942028985507244\n",
      "[+] Validation Batch No: 12 done. Percent Completion: 17.391304347826086\n",
      "[+] Validation Batch No: 13 done. Percent Completion: 18.84057971014493\n",
      "[+] Validation Batch No: 14 done. Percent Completion: 20.28985507246377\n",
      "[+] Validation Batch No: 15 done. Percent Completion: 21.73913043478261\n",
      "[+] Validation Batch No: 16 done. Percent Completion: 23.18840579710145\n",
      "[+] Validation Batch No: 17 done. Percent Completion: 24.637681159420293\n",
      "[+] Validation Batch No: 18 done. Percent Completion: 26.08695652173913\n",
      "[+] Validation Batch No: 19 done. Percent Completion: 27.536231884057973\n",
      "[+] Validation Batch No: 20 done. Percent Completion: 28.985507246376812\n",
      "[+] Validation Batch No: 21 done. Percent Completion: 30.434782608695656\n",
      "[+] Validation Batch No: 22 done. Percent Completion: 31.88405797101449\n",
      "[+] Validation Batch No: 23 done. Percent Completion: 33.33333333333333\n",
      "[+] Validation Batch No: 24 done. Percent Completion: 34.78260869565217\n",
      "[+] Validation Batch No: 25 done. Percent Completion: 36.231884057971016\n",
      "[+] Validation Batch No: 26 done. Percent Completion: 37.68115942028986\n",
      "[+] Validation Batch No: 27 done. Percent Completion: 39.130434782608695\n",
      "[+] Validation Batch No: 28 done. Percent Completion: 40.57971014492754\n",
      "[+] Validation Batch No: 29 done. Percent Completion: 42.028985507246375\n",
      "[+] Validation Batch No: 30 done. Percent Completion: 43.47826086956522\n",
      "[+] Validation Batch No: 31 done. Percent Completion: 44.927536231884055\n",
      "[+] Validation Batch No: 32 done. Percent Completion: 46.3768115942029\n",
      "[+] Validation Batch No: 33 done. Percent Completion: 47.82608695652174\n",
      "[+] Validation Batch No: 34 done. Percent Completion: 49.275362318840585\n",
      "[+] Validation Batch No: 35 done. Percent Completion: 50.72463768115942\n",
      "[+] Validation Batch No: 36 done. Percent Completion: 52.17391304347826\n",
      "[+] Validation Batch No: 37 done. Percent Completion: 53.62318840579711\n",
      "[+] Validation Batch No: 38 done. Percent Completion: 55.072463768115945\n",
      "[+] Validation Batch No: 39 done. Percent Completion: 56.52173913043478\n",
      "[+] Validation Batch No: 40 done. Percent Completion: 57.971014492753625\n",
      "[+] Validation Batch No: 41 done. Percent Completion: 59.42028985507246\n",
      "[+] Validation Batch No: 42 done. Percent Completion: 60.86956521739131\n",
      "[+] Validation Batch No: 43 done. Percent Completion: 62.31884057971014\n",
      "[+] Validation Batch No: 44 done. Percent Completion: 63.76811594202898\n",
      "[+] Validation Batch No: 45 done. Percent Completion: 65.21739130434783\n",
      "[+] Validation Batch No: 46 done. Percent Completion: 66.66666666666666\n",
      "[+] Validation Batch No: 47 done. Percent Completion: 68.11594202898551\n",
      "[+] Validation Batch No: 48 done. Percent Completion: 69.56521739130434\n",
      "[+] Validation Batch No: 49 done. Percent Completion: 71.01449275362319\n",
      "[+] Validation Batch No: 50 done. Percent Completion: 72.46376811594203\n",
      "[+] Validation Batch No: 51 done. Percent Completion: 73.91304347826086\n",
      "[+] Validation Batch No: 52 done. Percent Completion: 75.36231884057972\n",
      "[+] Validation Batch No: 53 done. Percent Completion: 76.81159420289855\n",
      "[+] Validation Batch No: 54 done. Percent Completion: 78.26086956521739\n",
      "[+] Validation Batch No: 55 done. Percent Completion: 79.71014492753623\n",
      "[+] Validation Batch No: 56 done. Percent Completion: 81.15942028985508\n",
      "[+] Validation Batch No: 57 done. Percent Completion: 82.6086956521739\n",
      "[+] Validation Batch No: 58 done. Percent Completion: 84.05797101449275\n",
      "[+] Validation Batch No: 59 done. Percent Completion: 85.5072463768116\n",
      "[+] Validation Batch No: 60 done. Percent Completion: 86.95652173913044\n",
      "[+] Validation Batch No: 61 done. Percent Completion: 88.40579710144928\n",
      "[+] Validation Batch No: 62 done. Percent Completion: 89.85507246376811\n",
      "[+] Validation Batch No: 63 done. Percent Completion: 91.30434782608695\n",
      "[+] Validation Batch No: 64 done. Percent Completion: 92.7536231884058\n",
      "[+] Validation Batch No: 65 done. Percent Completion: 94.20289855072464\n",
      "[+] Validation Batch No: 66 done. Percent Completion: 95.65217391304348\n",
      "[+] Validation Batch No: 67 done. Percent Completion: 97.10144927536231\n",
      "[+] Validation Batch No: 68 done. Percent Completion: 98.55072463768117\n",
      "[+] Validation Batch No: 69 done. Percent Completion: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 12:42:34.287574: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "accuracy = validate_model(pruned_pose_model, val_dataset, len(list(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Pruned model with pruning metadata removed accuracy:  61.608775137111515\n"
     ]
    }
   ],
   "source": [
    "print(\"[+] Pruned model with pruning metadata removed accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Total Params:  5784828  number of weights pruned:  2185495  percent pruned:  37.779774956143896\n"
     ]
    }
   ],
   "source": [
    "total_params, pruned_params, prune_ratio = find_unstructured_prune_ratio(pruned_pose_model)\n",
    "print(\"[+] Total Params: \", total_params, \" number of weights pruned: \", pruned_params, \" percent pruned: \", prune_ratio * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pruned_pose_model, './pruned_models/pruned_pose_classificaiton_model_1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now after removing the pruning metadata we compare the model sizes again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File compressed successfully: ./compressed_models/pruned_pose_classification_torch_1.gz\n"
     ]
    }
   ],
   "source": [
    "compress_file('./pruned_models/pruned_pose_classificaiton_model_1.pth', './compressed_models/pruned_pose_classification_torch_1.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of compressed file './pose_classification_model/pose_classificaiton_model_torch_0.pth': 82597522 bytes\n",
      "Size of compressed file './pruned_models/pruned_pose_classificaiton_model_1.pth': 82597915 bytes\n",
      "Size of compressed file './compressed_models/pose_classification_torch.gz': 69856912 bytes\n",
      "Size of compressed file './compressed_models/pruned_pose_classification_torch_1.gz': 63433575 bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Orginial uncompressed: 82.597522 MB',\n",
       " 'Orginial compressed: 69.856912 MB',\n",
       " 'Pruned uncompressed: 82.597915 MB',\n",
       " 'Pruned compressed: 63.433575 MB')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_uncompressed_size, pruned_uncompressed_size = get_compressed_file_size('./pose_classification_model/pose_classificaiton_model_torch_0.pth'), get_compressed_file_size('./pruned_models/pruned_pose_classificaiton_model_1.pth')\n",
    "original_compressed_size, pruned_compressed_size = get_compressed_file_size('./compressed_models/pose_classification_torch.gz'), get_compressed_file_size('./compressed_models/pruned_pose_classification_torch_1.gz')\n",
    "f'Orginial uncompressed: {original_uncompressed_size / 1e6} MB', f'Orginial compressed: {original_compressed_size / 1e6} MB', f'Pruned uncompressed: {pruned_uncompressed_size / 1e6} MB', f'Pruned compressed: {pruned_compressed_size / 1e6} MB'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the compressed file of the pruned model is a lot less in size than the compressed file of the unpruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Reduction in pruned model compressed file size:  9.194991327415103\n"
     ]
    }
   ],
   "source": [
    "reduction_in_size = ((original_compressed_size - pruned_compressed_size) / original_compressed_size) * 100\n",
    "print(\"[+] Reduction in pruned model compressed file size: \", reduction_in_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have achieved 10% reduction in file size with pruning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aditya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
